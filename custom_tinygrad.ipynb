{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/geohot/tinygrad.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd tinygrad/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, sys\n",
    "import json\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tinygrad.tensor import Tensor\n",
    "from tinygrad.nn import optim, BatchNorm2d\n",
    "import tinygrad.nn as nn\n",
    "from tinygrad.helpers import flatten\n",
    "from tinygrad.nn.optim import SGD, Adam\n",
    "from sklearn.datasets import fetch_openml\n",
    "from tinygrad.state import safe_save, safe_load, get_state_dict, load_state_dict, torch_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = 'Dataset'\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Iterate through the cat images\n",
    "cat_dir = os.path.join(dataset_dir, 'Cat')\n",
    "for filename in os.listdir(cat_dir):\n",
    "    if filename.endswith('.jpg'):\n",
    "        image_path = os.path.join(cat_dir, filename)\n",
    "        image = Image.open(image_path).convert('RGB')  \n",
    "        image = image.resize((256, 256))\n",
    "        images.append(np.array(image)/255)\n",
    "        labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "dog_dir = os.path.join(dataset_dir, 'Dog')\n",
    "for filename in os.listdir(dog_dir):\n",
    "    if filename.endswith('.jpg'):\n",
    "        image_path = os.path.join(dog_dir, filename)\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image = image.resize((256, 256))\n",
    "        images.append(np.array(image)/255)\n",
    "        labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(zip(images, labels))\n",
    "random.shuffle(data)\n",
    "\n",
    "shuffled_images, shuffled_labels = zip(*data)\n",
    "\n",
    "shuffled_images = np.array(shuffled_images, dtype=np.float64)\n",
    "shuffled_labels = np.array(shuffled_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24998, 224, 224), (24998,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_images.shape, shuffled_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTinyNet:\n",
    "    def __init__(self):\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=64*6*6, out_features=500)\n",
    "        self.fc2 = nn.Linear(in_features=500, out_features=50)\n",
    "        self.fc3 = nn.Linear(in_features=50, out_features=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(\"Before Reshape: \", x.shape)\n",
    "        x = x.reshape((x.shape[0], 3, 256, 256))\n",
    "        # print(\"Before Conv-1: \", x.shape)\n",
    "        x = self.conv1(x)\n",
    "        x = x.leakyrelu()\n",
    "        # print(\"After Conv-1+relu: \", x.shape)\n",
    "        x = x.max_pool2d(2)  \n",
    "        # print(\"After Pooling-1: \", x.shape)\n",
    "        \n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = x.leakyrelu()\n",
    "        # print(\"After Conv-2+relu: \", x.shape)\n",
    "        x = x.max_pool2d(2) \n",
    "        # print(\"After Pooling-2: \", x.shape) \n",
    "       \n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = x.leakyrelu()\n",
    "        # print(\"After Conv-3+relu: \", x.shape)\n",
    "        x = x.max_pool2d(2)  \n",
    "        # print(\"After Pooling-3: \", x.shape)\n",
    "       \n",
    "\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        # print(\"After Flatten: \", x.shape)\n",
    "\n",
    "        x = self.fc1(x) \n",
    "        x = x.leakyrelu()\n",
    "        # print(\"After FC-1: \", x.shape)\n",
    "\n",
    "        x = self.fc2(x) \n",
    "        x = x.leakyrelu()\n",
    "        # print(\"After FC-2: \", x.shape)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        # print(\"After FC-3: \", x.shape) \n",
    "        return x.log_softmax()\n",
    "\n",
    "net = CustomTinyNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensor.training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_crossentropy(out, Y):\n",
    "  num_classes = out.shape[-1]\n",
    "  YY = Y.flatten().astype(np.int32)\n",
    "  y = np.zeros((YY.shape[0], num_classes), np.float32)\n",
    "  # correct loss for NLL, torch NLL loss returns one per row\n",
    "  y[range(y.shape[0]),YY] = -1.0*num_classes\n",
    "  y = y.reshape(list(Y.shape)+[num_classes])\n",
    "  y = Tensor(y)\n",
    "  return out.mul(y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam([net.conv1.weight, net.conv2.weight, net.conv3.weight], lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken: 1.8s, Epoch [1/2500], Loss: 0.69440, Accuracy: 0.40000\n",
      "Time Taken: 19.9s, Epoch [101/2500], Loss: 0.69202, Accuracy: 0.58000\n",
      "Time Taken: 16.7s, Epoch [201/2500], Loss: 0.69342, Accuracy: 0.47000\n",
      "Time Taken: 17.4s, Epoch [301/2500], Loss: 0.69304, Accuracy: 0.51000\n",
      "Time Taken: 16.8s, Epoch [401/2500], Loss: 0.69204, Accuracy: 0.58000\n",
      "Time Taken: 18.7s, Epoch [501/2500], Loss: 0.69369, Accuracy: 0.45000\n",
      "Time Taken: 16.7s, Epoch [601/2500], Loss: 0.69329, Accuracy: 0.49000\n",
      "Time Taken: 21.8s, Epoch [701/2500], Loss: 0.69417, Accuracy: 0.42000\n",
      "Time Taken: 19.4s, Epoch [801/2500], Loss: 0.69284, Accuracy: 0.52000\n",
      "Time Taken: 19.5s, Epoch [901/2500], Loss: 0.69226, Accuracy: 0.57000\n",
      "Time Taken: 17.5s, Epoch [1001/2500], Loss: 0.69340, Accuracy: 0.47000\n",
      "Time Taken: 17.5s, Epoch [1101/2500], Loss: 0.69301, Accuracy: 0.51000\n",
      "Time Taken: 17.6s, Epoch [1201/2500], Loss: 0.69341, Accuracy: 0.47000\n",
      "Time Taken: 17.8s, Epoch [1301/2500], Loss: 0.69421, Accuracy: 0.41000\n",
      "Time Taken: 18.9s, Epoch [1401/2500], Loss: 0.69326, Accuracy: 0.50000\n",
      "Time Taken: 18.9s, Epoch [1501/2500], Loss: 0.69284, Accuracy: 0.52000\n",
      "Time Taken: 17.1s, Epoch [1601/2500], Loss: 0.69345, Accuracy: 0.48000\n",
      "Time Taken: 19.5s, Epoch [1701/2500], Loss: 0.69320, Accuracy: 0.49000\n",
      "Time Taken: 19.0s, Epoch [1801/2500], Loss: 0.69275, Accuracy: 0.53000\n",
      "Time Taken: 16.9s, Epoch [1901/2500], Loss: 0.69481, Accuracy: 0.38000\n",
      "Time Taken: 18.4s, Epoch [2001/2500], Loss: 0.69341, Accuracy: 0.47000\n",
      "Time Taken: 20.5s, Epoch [2101/2500], Loss: 0.69211, Accuracy: 0.57000\n",
      "Time Taken: 21.8s, Epoch [2201/2500], Loss: 0.69228, Accuracy: 0.56000\n",
      "Time Taken: 20.4s, Epoch [2301/2500], Loss: 0.69242, Accuracy: 0.56000\n",
      "Time Taken: 19.8s, Epoch [2401/2500], Loss: 0.69275, Accuracy: 0.52000\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 2500\n",
    "\n",
    "running_loss, correct, total = 0.0, 0.0, 0.0\n",
    "start_time = time.time()\n",
    "\n",
    "file_write = open(\"output.txt\", \"a\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    samp = np.random.randint(0, shuffled_images.shape[0], size=(128))\n",
    "    batch = Tensor(shuffled_images[samp].astype(np.float32), requires_grad=False)\n",
    "    labels_batch = shuffled_labels[samp]\n",
    "    \n",
    "    num_zeros = list(labels_batch).count(0)\n",
    "    num_ones = list(labels_batch).count(1)\n",
    "    # print(f\"Zeros: {num_zeros}\\tOnes: {num_ones}\")\n",
    "    \n",
    "\n",
    "    out = net.forward(batch)\n",
    "\n",
    "    loss = categorical_crossentropy(out, labels_batch)\n",
    "    \n",
    "    opt.zero_grad()\n",
    "\n",
    "    loss.backward()\n",
    "    \n",
    "\n",
    "    pred = np.argmax(out.numpy().data, axis=-1)\n",
    "\n",
    "    accuracies = [1 if prediction == actual_label else 0 for prediction, actual_label in zip(pred, labels_batch)]\n",
    "    mean_accuracy = sum(accuracies) / len(accuracies)\n",
    "\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Time Taken: {time.time()-start_time:.1f}s, Epoch [{epoch+1}/{num_epochs}], Loss: {loss.numpy():.5f}, Accuracy: {mean_accuracy:.5f}\")\n",
    "        \n",
    "        file_write.write(f\"Epochs: {epoch+1}/{num_epochs}\\tLoss: {loss.numpy():.5f}\\tAccuracy: {mean_accuracy:.5f}\\tActual-label: {labels_batch}\\tPrediction: {pred}\\n\")\n",
    "        start_time = time.time()\n",
    "    \n",
    "\n",
    "file_write.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.51\n",
      "Time Taken To Test: 249.4559848000008\n"
     ]
    }
   ],
   "source": [
    "# set training flag to false\n",
    "Tensor.training = False\n",
    "\n",
    "st = time.perf_counter()\n",
    "avg_acc = 0\n",
    "for step in range(2000):\n",
    "  # random sample a batch\n",
    "  samp = np.random.randint(0, shuffled_images.shape[0], size=(128))\n",
    "  batch = Tensor(shuffled_images[samp].astype('float32'), requires_grad=False)\n",
    "  \n",
    "  # get the corresponding labels\n",
    "  batch_labels = shuffled_labels[samp]\n",
    "\n",
    "  # forward pass\n",
    "  out = net.forward(batch)\n",
    "\n",
    "  # calculate accuracy\n",
    "  pred = np.argmax(out.numpy(), axis=-1)\n",
    "\n",
    "  # labels = [label for label in batch_labels]\n",
    "  accuracies = [1 if prediction == actual_label else 0 for prediction, actual_label in zip(pred, labels_batch)]\n",
    "  mean_accuracy = sum(accuracies) / len(accuracies)\n",
    "\n",
    "print(f\"Test Accuracy: {mean_accuracy}\")\n",
    "print(f\"Time Taken To Test: {time.perf_counter() - st}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we need the state dict of our model\n",
    "state_dict = get_state_dict(net)\n",
    "\n",
    "# then we can just save it to a file\n",
    "safe_save(state_dict, \"model/model.safetensors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ram used:  0.01 GB, fc3.bias                                          : 100%|██████████| 12/12 [00:00<00:00, 336.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded weights in 39.36 ms, 0.01 GB loaded at 0.25 GB/s\n",
      "\n",
      "\n",
      "Time Taken to Predict the class:  0.0174\n",
      "Predicted class: [1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tinygrad.tensor as tensor\n",
    "from PIL import Image\n",
    "# Step 1: Preprocess the image\n",
    "image = Image.open('Dataset/Cat/0.jpg').convert('L')\n",
    "image = image.resize((256, 256))\n",
    "\n",
    "# Step 2: Load the trained model\n",
    "state_dict = safe_load(\"model/model.safetensors\")\n",
    "\n",
    "checkpoints = {\n",
    "    'conv1.weight': state_dict['conv1.weight'],\n",
    "    'conv1.bias': state_dict['conv1.bias'],\n",
    "    'conv2.weight': state_dict['conv2.weight'],\n",
    "    'conv2.bias': state_dict['conv2.bias'],\n",
    "    'conv3.weight': state_dict['conv3.weight'],\n",
    "    'conv3.bias': state_dict['conv3.bias'],\n",
    "    'fc1.weight': state_dict['fc1.weight'],\n",
    "    'fc1.bias': state_dict['fc1.bias'],\n",
    "    'fc2.weight': state_dict['fc2.weight'],\n",
    "    'fc2.bias': state_dict['fc2.bias'],\n",
    "    'fc3.weight': state_dict['fc3.weight'],\n",
    "    'fc3.bias': state_dict['fc3.bias']\n",
    "}\n",
    "\n",
    "model = CustomTinyNet()\n",
    "\n",
    "load_state_dict(model, checkpoints)\n",
    "\n",
    "\n",
    "image = np.array(image)\n",
    "\n",
    "image = image.astype(np.float32) / 255.0  \n",
    "\n",
    "start_time = time.time()\n",
    "preprocessed_image = image.reshape((1, 3, 256, 256))\n",
    "\n",
    "# Step 3: Forward pass\n",
    "input_tensor = tensor.Tensor(preprocessed_image)  \n",
    "output_tensor = net.forward(input_tensor)  \n",
    "\n",
    "print(f\"\\n\\nTime Taken to Predict the class: {time.time() - start_time: .4f}\")\n",
    "\n",
    "# Step 4: Obtain predictions\n",
    "predicted_class= np.argmax(output_tensor.numpy(), axis=-1)\n",
    "print(\"Predicted class:\", predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fa1a39b4d220832bc88fa9bccaa17b58fb936972f35e194156c0c6b088907f4d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
