{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'tinygrad' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/geohot/tinygrad.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ahmad-mujtaba/Ahmad_Mujtaba/python_work/Tinygrad_Learning_Projects/tinygrad\n"
     ]
    }
   ],
   "source": [
    "cd tinygrad/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Obtaining file:///home/ahmad-mujtaba/Ahmad_Mujtaba/python_work/Tinygrad_Learning_Projects/tinygrad\n",
      "Requirement already satisfied: PyYAML in /home/ahmad-mujtaba/Ahmad_Mujtaba/python_work/Tinygrad_Learning_Projects/venv/lib/python3.8/site-packages (from tinygrad==0.6.0) (6.0)\n",
      "Requirement already satisfied: networkx in /home/ahmad-mujtaba/Ahmad_Mujtaba/python_work/Tinygrad_Learning_Projects/venv/lib/python3.8/site-packages (from tinygrad==0.6.0) (3.1)\n",
      "Requirement already satisfied: numpy in /home/ahmad-mujtaba/Ahmad_Mujtaba/python_work/Tinygrad_Learning_Projects/venv/lib/python3.8/site-packages (from tinygrad==0.6.0) (1.24.4)\n",
      "Requirement already satisfied: pillow in /home/ahmad-mujtaba/Ahmad_Mujtaba/python_work/Tinygrad_Learning_Projects/venv/lib/python3.8/site-packages (from tinygrad==0.6.0) (10.0.0)\n",
      "Requirement already satisfied: pyopencl in /home/ahmad-mujtaba/Ahmad_Mujtaba/python_work/Tinygrad_Learning_Projects/venv/lib/python3.8/site-packages (from tinygrad==0.6.0) (2023.1.1)\n",
      "Requirement already satisfied: requests in /home/ahmad-mujtaba/Ahmad_Mujtaba/python_work/Tinygrad_Learning_Projects/venv/lib/python3.8/site-packages (from tinygrad==0.6.0) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /home/ahmad-mujtaba/Ahmad_Mujtaba/python_work/Tinygrad_Learning_Projects/venv/lib/python3.8/site-packages (from tinygrad==0.6.0) (4.65.0)\n",
      "Requirement already satisfied: pytools>=2021.2.7 in /home/ahmad-mujtaba/Ahmad_Mujtaba/python_work/Tinygrad_Learning_Projects/venv/lib/python3.8/site-packages (from pyopencl->tinygrad==0.6.0) (2023.1)\n",
      "Requirement already satisfied: platformdirs>=2.2.0 in /home/ahmad-mujtaba/Ahmad_Mujtaba/python_work/Tinygrad_Learning_Projects/venv/lib/python3.8/site-packages (from pyopencl->tinygrad==0.6.0) (3.8.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ahmad-mujtaba/Ahmad_Mujtaba/python_work/Tinygrad_Learning_Projects/venv/lib/python3.8/site-packages (from requests->tinygrad==0.6.0) (3.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ahmad-mujtaba/Ahmad_Mujtaba/python_work/Tinygrad_Learning_Projects/venv/lib/python3.8/site-packages (from requests->tinygrad==0.6.0) (2023.5.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ahmad-mujtaba/Ahmad_Mujtaba/python_work/Tinygrad_Learning_Projects/venv/lib/python3.8/site-packages (from requests->tinygrad==0.6.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ahmad-mujtaba/Ahmad_Mujtaba/python_work/Tinygrad_Learning_Projects/venv/lib/python3.8/site-packages (from requests->tinygrad==0.6.0) (2.0.3)\n",
      "Requirement already satisfied: typing-extensions>=4.0; python_version < \"3.11\" in /home/ahmad-mujtaba/Ahmad_Mujtaba/python_work/Tinygrad_Learning_Projects/venv/lib/python3.8/site-packages (from pytools>=2021.2.7->pyopencl->tinygrad==0.6.0) (4.7.1)\n",
      "Installing collected packages: tinygrad\n",
      "  Attempting uninstall: tinygrad\n",
      "    Found existing installation: tinygrad 0.6.0\n",
      "    Uninstalling tinygrad-0.6.0:\n",
      "      Successfully uninstalled tinygrad-0.6.0\n",
      "  Running setup.py develop for tinygrad\n",
      "Successfully installed tinygrad\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ahmad-mujtaba/Ahmad_Mujtaba/python_work/Tinygrad_Learning_Projects'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, sys\n",
    "import json\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tinygrad.tensor import Tensor\n",
    "from tinygrad.nn import optim, BatchNorm2d\n",
    "import tinygrad.nn as nn\n",
    "from tinygrad.helpers import flatten\n",
    "from tinygrad.nn.optim import SGD, Adam\n",
    "from sklearn.datasets import fetch_openml\n",
    "from tinygrad.state import safe_save, safe_load, get_state_dict, load_state_dict, torch_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ahmad-mujtaba/Ahmad_Mujtaba/python_work/Tinygrad_Learning_Projects\n"
     ]
    }
   ],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = 'Dataset'\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Iterate through the cat images\n",
    "cat_dir = os.path.join(dataset_dir, 'Cat')\n",
    "for filename in os.listdir(cat_dir):\n",
    "    if filename.endswith('.jpg'):\n",
    "        image_path = os.path.join(cat_dir, filename)\n",
    "        image = Image.open(image_path).convert('L')  \n",
    "        image = image.resize((150, 150))\n",
    "        images.append(np.array(image))\n",
    "        labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmad-mujtaba/Ahmad_Mujtaba/python_work/Tinygrad_Learning_Projects/venv/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:866: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    }
   ],
   "source": [
    "dog_dir = os.path.join(dataset_dir, 'Dog')\n",
    "for filename in os.listdir(dog_dir):\n",
    "    if filename.endswith('.jpg'):\n",
    "        image_path = os.path.join(dog_dir, filename)\n",
    "        image = Image.open(image_path).convert('L')\n",
    "        image = image.resize((150, 150))\n",
    "        images.append(np.array(image))\n",
    "        labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(zip(images, labels))\n",
    "random.shuffle(data)\n",
    "\n",
    "shuffled_images, shuffled_labels = zip(*data)\n",
    "\n",
    "shuffled_images = np.array(shuffled_images)\n",
    "shuffled_labels = np.array(shuffled_labels)\n",
    "\n",
    "shuffled_images = Tensor(shuffled_images)\n",
    "shuffled_labels = Tensor(shuffled_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24998, 150, 150), (24998,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_images.shape, shuffled_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTinyNet:\n",
    "    def __init__(self):\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=128, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(in_channels=128, out_channels=64, kernel_size=3)\n",
    "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=512, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(in_features=512*15*15, out_features=32)\n",
    "        self.fc2 = nn.Linear(in_features=32, out_features=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape((x.shape[0], 1, 150, 150))\n",
    "        x = self.conv1(x)\n",
    "        x = x.relu()\n",
    "        x = x.max_pool2d(2)  \n",
    "        x = x.dropout(0.2)  \n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = x.relu()\n",
    "        x = x.max_pool2d(2)  \n",
    "        x = x.dropout(0.2) \n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = x.relu()\n",
    "        x = x.max_pool2d(2)  \n",
    "        x = x.dropout(0.5) \n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = x.relu()\n",
    "        x = x.dropout(0.2) \n",
    "\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "\n",
    "        x = self.fc1(x) \n",
    "        x = x.relu()\n",
    "\n",
    "        x = self.fc2(x) \n",
    "        return x.sigmoid()\n",
    "\n",
    "net = CustomTinyNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensor.training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cross_entropy(out, Y):\n",
    "    epsilon = 1e-7 \n",
    "    loss = -Y * Tensor.log(out + epsilon) - (1 - Y) * Tensor.log(1 - out + epsilon)\n",
    "    loss = [float(l.numpy()[0]) for l in loss]\n",
    "    \n",
    "    return Tensor(np.mean(loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = SGD([net.conv1.weight, net.conv2.weight, net.conv3.weight, net.conv4.weight], lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken: 3.2s, Epoch [1/1000], Loss: 0.69500, Accuracy: 0.45312\n",
      "Time Taken: 97.0s, Epoch [101/1000], Loss: 0.68808, Accuracy: 0.62500\n",
      "Time Taken: 97.2s, Epoch [201/1000], Loss: 0.69268, Accuracy: 0.51562\n",
      "Time Taken: 96.0s, Epoch [301/1000], Loss: 0.69764, Accuracy: 0.35938\n",
      "Time Taken: 96.4s, Epoch [401/1000], Loss: 0.69222, Accuracy: 0.53125\n",
      "Time Taken: 97.1s, Epoch [501/1000], Loss: 0.69476, Accuracy: 0.46875\n",
      "Time Taken: 97.0s, Epoch [601/1000], Loss: 0.69561, Accuracy: 0.45312\n",
      "Time Taken: 97.4s, Epoch [701/1000], Loss: 0.69395, Accuracy: 0.43750\n",
      "Time Taken: 97.1s, Epoch [801/1000], Loss: 0.69386, Accuracy: 0.48438\n",
      "Time Taken: 97.5s, Epoch [901/1000], Loss: 0.69178, Accuracy: 0.54688\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1000\n",
    "\n",
    "running_loss, correct, total = 0.0, 0.0, 0.0\n",
    "start_time = time.time()\n",
    "\n",
    "file_write = open(\"output.txt\", \"a\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Randomly sample a batch\n",
    "    samp = np.random.randint(0, shuffled_images.shape[0], size=(64))\n",
    "    batch = Tensor(shuffled_images.numpy()[samp].astype('float32') / 255.0, requires_grad=False)\n",
    "    # Get the corresponding labels\n",
    "    labels_batch = shuffled_labels.numpy()[samp]\n",
    "\n",
    "    # Forward pass\n",
    "    out = net.forward(batch)\n",
    "\n",
    "    # Compute loss\n",
    "    loss = binary_cross_entropy(out, labels_batch)\n",
    "    \n",
    "    # Zero gradients\n",
    "    opt.zero_grad()\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Calculate accuracy\n",
    "    pred = np.argmax(out.numpy().data, axis=-1)\n",
    "    acc = (pred == labels_batch).mean()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Time Taken: {time.time()-start_time:.1f}s, Epoch [{epoch+1}/{num_epochs}], Loss: {loss.numpy():.5f}, Accuracy: {acc:.5f}\")\n",
    "        \n",
    "        file_write.write(f\"Epochs: {epoch+1}/{num_epochs}\\tLoss: {loss.numpy():.5f}\\tAccuracy: {acc:.5f}\\tActual-label: {labels_batch}\\tPrediction: {pred}\\n\")\n",
    "        start_time = time.time()\n",
    "    \n",
    "\n",
    "file_write.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.498703125\n",
      "Time Taken To Test: 896.732031386\n"
     ]
    }
   ],
   "source": [
    "# set training flag to false\n",
    "Tensor.training = False\n",
    "\n",
    "st = time.perf_counter()\n",
    "avg_acc = 0\n",
    "for step in range(1000):\n",
    "  # random sample a batch\n",
    "  samp = np.random.randint(0, shuffled_images.shape[0], size=(64))\n",
    "  batch = Tensor(shuffled_images.numpy()[samp].astype('float32') / 255.0, requires_grad=False)\n",
    "  \n",
    "  # get the corresponding labels\n",
    "  batch_labels = shuffled_labels.numpy()[samp]\n",
    "\n",
    "  # forward pass\n",
    "  out = net.forward(batch)\n",
    "\n",
    "  # calculate accuracy\n",
    "  pred = np.argmax(out.numpy(), axis=-1)\n",
    "\n",
    "  labels = [label for label in batch_labels]\n",
    "  avg_acc += (pred == labels).mean()\n",
    "\n",
    "print(f\"Test Accuracy: {avg_acc / 1000}\")\n",
    "print(f\"Time Taken To Test: {time.perf_counter() - st}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we need the state dict of our model\n",
    "state_dict = get_state_dict(net)\n",
    "\n",
    "# then we can just save it to a file\n",
    "safe_save(state_dict, \"model/model.safetensors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ram used:  1.14 GB, fc2.bias                                          : 100%|██████████| 12/12 [00:00<00:00, 294.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded weights in 43.86 ms, 1.14 GB loaded at 25.88 GB/s\n",
      "\n",
      "\n",
      "Time Taken to Predict the class:  0.0181\n",
      "Predicted class: [0]\n"
     ]
    }
   ],
   "source": [
    "import tinygrad.tensor as tensor\n",
    "from PIL import Image\n",
    "# Step 1: Preprocess the image\n",
    "image = Image.open('Dataset/Dog/0.jpg').convert('L')\n",
    "image = image.resize((150, 150))\n",
    "\n",
    "# Step 2: Load the trained model\n",
    "state_dict = safe_load(\"model/model.safetensors\")\n",
    "\n",
    "checkpoints = {\n",
    "    'conv1.weight': state_dict['conv1.weight'],\n",
    "    'conv1.bias': state_dict['conv1.bias'],\n",
    "    'conv2.weight': state_dict['conv2.weight'],\n",
    "    'conv2.bias': state_dict['conv2.bias'],\n",
    "    'conv3.weight': state_dict['conv3.weight'],\n",
    "    'conv3.bias': state_dict['conv3.bias'],\n",
    "    'conv4.weight': state_dict['conv4.weight'],\n",
    "    'conv4.bias': state_dict['conv4.bias'],\n",
    "    'fc1.weight': state_dict['fc1.weight'],\n",
    "    'fc1.bias': state_dict['fc1.bias'],\n",
    "    'fc2.weight': state_dict['fc2.weight'],\n",
    "    'fc2.bias': state_dict['fc2.bias']\n",
    "}\n",
    "\n",
    "model = CustomTinyNet()\n",
    "\n",
    "load_state_dict(model, checkpoints)\n",
    "\n",
    "\n",
    "image = np.array(image)\n",
    "\n",
    "image = image.astype(np.float32) / 255.0  \n",
    "\n",
    "start_time = time.time()\n",
    "preprocessed_image = image.reshape((1, 1, 150, 150))\n",
    "\n",
    "# Step 3: Forward pass\n",
    "input_tensor = tensor.Tensor(preprocessed_image)  \n",
    "output_tensor = net.forward(input_tensor)  \n",
    "\n",
    "print(f\"\\n\\nTime Taken to Predict the class: {time.time() - start_time: .4f}\")\n",
    "\n",
    "# Step 4: Obtain predictions\n",
    "predicted_class= np.argmax(output_tensor.numpy(), axis=-1)\n",
    "print(\"Predicted class:\", predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fa1a39b4d220832bc88fa9bccaa17b58fb936972f35e194156c0c6b088907f4d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
