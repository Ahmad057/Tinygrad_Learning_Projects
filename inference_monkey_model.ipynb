{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, sys\n",
    "import json\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tinygrad.tensor import Tensor\n",
    "from tinygrad.nn import optim, BatchNorm2d\n",
    "import tinygrad.nn as nn\n",
    "from tinygrad.helpers import flatten\n",
    "from tinygrad.nn.optim import SGD, Adam\n",
    "from sklearn.datasets import fetch_openml\n",
    "from tinygrad.state import safe_save, safe_load, get_state_dict, load_state_dict, torch_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = {}\n",
    "file = open(\"weights_bias/monkey_weight_bias_model.txt\", \"r\")\n",
    "\n",
    "conv1_weights = file.readline()\n",
    "conv1_bias = file.readline()\n",
    "\n",
    "conv2_weights = file.readline()\n",
    "conv2_bias = file.readline()\n",
    "\n",
    "conv3_weights = file.readline()\n",
    "conv3_bias = file.readline()\n",
    "\n",
    "fc1_weights = file.readline()\n",
    "fc1_bias = file.readline()\n",
    "\n",
    "fc2_weights = file.readline()\n",
    "fc2_bias = file.readline()\n",
    "\n",
    "fc3_weights = file.readline()\n",
    "fc3_bias = file.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_weight_bias_format(data, shape):\n",
    "    data = data.split(\" \")\n",
    "    data = list(map(float, data))\n",
    "    return np.array(data).reshape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1_weights = set_weight_bias_format(conv1_weights, (16, 3, 3, 3))\n",
    "conv1_bias = set_weight_bias_format(conv1_bias, 16)\n",
    "\n",
    "conv2_weights = set_weight_bias_format(conv2_weights, (32, 16, 3, 3))\n",
    "conv2_bias = set_weight_bias_format(conv2_bias, (32))\n",
    "\n",
    "conv3_weights = set_weight_bias_format(conv3_weights, (64, 32, 3, 3))\n",
    "conv3_bias = set_weight_bias_format(conv3_bias, (64))\n",
    "\n",
    "fc1_weights = set_weight_bias_format(fc1_weights, (100, 1024))\n",
    "fc1_bias = set_weight_bias_format(fc1_bias, (100))\n",
    "\n",
    "fc2_weights = set_weight_bias_format(fc2_weights, (50, 100))\n",
    "fc2_bias = set_weight_bias_format(fc2_bias, (50))\n",
    "\n",
    "fc3_weights = set_weight_bias_format(fc3_weights, (10, 50))\n",
    "fc3_bias = set_weight_bias_format(fc3_bias, (10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict[\"conv1.weight\"] = Tensor(conv1_weights.astype(np.float32))\n",
    "state_dict[\"conv1.bias\"] = Tensor(conv1_bias.astype(np.float32))\n",
    "\n",
    "state_dict[\"conv2.weight\"] = Tensor(conv2_weights.astype(np.float32))\n",
    "state_dict[\"conv2.bias\"] = Tensor(conv2_bias.astype(np.float32))\n",
    "\n",
    "state_dict[\"conv3.weight\"] = Tensor(conv3_weights.astype(np.float32))\n",
    "state_dict[\"conv3.bias\"] = Tensor(conv3_bias.astype(np.float32))\n",
    "\n",
    "state_dict[\"fc1.weight\"] = Tensor(fc1_weights.astype(np.float32))\n",
    "state_dict[\"fc1.bias\"] = Tensor(fc1_bias.astype(np.float32))\n",
    "\n",
    "state_dict[\"fc2.weight\"] = Tensor(fc2_weights.astype(np.float32))\n",
    "state_dict[\"fc2.bias\"] = Tensor(fc2_bias.astype(np.float32))\n",
    "\n",
    "state_dict[\"fc3.weight\"] = Tensor(fc3_weights.astype(np.float32))\n",
    "state_dict[\"fc3.bias\"] = Tensor(fc3_bias.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ram used:  0.00 GB, fc3.bias                                          : 100%|██████████| 12/12 [00:00<00:00, 554.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded weights in 24.38 ms, 0.00 GB loaded at 0.08 GB/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class MonkeyTinyNet:\n",
    "    def __init__(self):\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=64*4*4, out_features=100)\n",
    "        self.fc2 = nn.Linear(in_features=100, out_features=50)\n",
    "        self.fc3 = nn.Linear(in_features=50, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape((x.shape[0], 3, 128, 128))\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = x.relu()\n",
    "        x = x.max_pool2d(2)  \n",
    "        # extract_feature_map(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = x.relu()\n",
    "        x = x.max_pool2d(2)        \n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = x.relu()\n",
    "        x = x.max_pool2d(2)         \n",
    "\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "\n",
    "        x = self.fc1(x) \n",
    "        x = x.relu()\n",
    "\n",
    "        x = self.fc2(x) \n",
    "        x = x.relu()\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        return x.log_softmax()\n",
    "        \n",
    "\n",
    "checkpoints = {\n",
    "    'conv1.weight': state_dict['conv1.weight'],\n",
    "    'conv1.bias': state_dict['conv1.bias'],\n",
    "    'conv2.weight': state_dict['conv2.weight'],\n",
    "    'conv2.bias': state_dict['conv2.bias'],\n",
    "    'conv3.weight': state_dict['conv3.weight'],\n",
    "    'conv3.bias': state_dict['conv3.bias'],\n",
    "    'fc1.weight': state_dict['fc1.weight'],\n",
    "    'fc1.bias': state_dict['fc1.bias'],\n",
    "    'fc2.weight': state_dict['fc2.weight'],\n",
    "    'fc2.bias': state_dict['fc2.bias'],\n",
    "    'fc3.weight': state_dict['fc3.weight'],\n",
    "    'fc3.bias': state_dict['fc3.bias']\n",
    "}\n",
    "\n",
    "model = MonkeyTinyNet()\n",
    "load_state_dict(model, checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "def pytorch_preprocessing(image):  \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),  # Apply the necessary transformations\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    image = transform(image)\n",
    "    image = image.unsqueeze(0) \n",
    "    return Tensor(image.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "monkey_classes = ['Emperor Tamarin', 'Gray Langur', 'Hamadryas Baboon', 'Proboscis Monkey', 'Vervet Monkey', \n",
    "                    'Golden Monkey', 'Mandril', 'Bald Uakari', 'White Faced Saki', 'Red Howler']\n",
    "\n",
    "def inference_model(image):\n",
    "    image = pytorch_preprocessing(image)\n",
    "    output_tensor = model.forward(image) \n",
    "\n",
    "    predicted_class= np.argmax(output_tensor.numpy(), axis=-1)\n",
    "    return monkey_classes[predicted_class[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: White Faced Saki\n",
      "Inference Time Taken:  0.014865398406982422\n"
     ]
    }
   ],
   "source": [
    "image = Image.open('test_img/White_Faced_Saki.jpg')\n",
    "pred_class =  inference_model(image)\n",
    "print(\"Predicted class:\", pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: Hamadryas Baboon\n",
      "Inference Time Taken:  0.009249448776245117\n"
     ]
    }
   ],
   "source": [
    "image = Image.open('test_img/Hamadryas_Baboon.jpg')\n",
    "pred_class = inference_model(image)\n",
    "print(\"Predicted class:\", pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Time Taken:  16.52835464477539\n",
      "Accuracy over 1306 Test Images: 0.7366003062787136\n"
     ]
    }
   ],
   "source": [
    "test_folder = \"monkey_test_data/\"\n",
    "each_folder = os.listdir(test_folder)\n",
    "\n",
    "acc = 0\n",
    "total_imgs = 0\n",
    "\n",
    "start_time = time.time()\n",
    "for folder in each_folder:\n",
    "    folder_path = os.path.join(test_folder, folder)\n",
    "    for img_name in os.listdir(folder_path):\n",
    "        image = Image.open(f\"{folder_path}/{img_name}\")\n",
    "        pred_class = inference_model(image)\n",
    "        if pred_class == folder:\n",
    "            acc+=1\n",
    "\n",
    "        total_imgs+=1\n",
    "\n",
    "print(\"Inference Time Taken: \", time.time()-start_time)\n",
    "print(f\"Accuracy over {total_imgs} Test Images: {acc/total_imgs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fa1a39b4d220832bc88fa9bccaa17b58fb936972f35e194156c0c6b088907f4d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
