{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhTLI2iJaPdS",
        "outputId": "f4c6b7d5-6c70-4ae4-94e6-c1d7b140d1c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'tinygrad'...\n",
            "remote: Enumerating objects: 14566, done.\u001b[K\n",
            "remote: Counting objects: 100% (1892/1892), done.\u001b[K\n",
            "remote: Compressing objects: 100% (387/387), done.\u001b[K\n",
            "remote: Total 14566 (delta 1690), reused 1587 (delta 1505), pack-reused 12674\u001b[K\n",
            "Receiving objects: 100% (14566/14566), 18.42 MiB | 24.56 MiB/s, done.\n",
            "Resolving deltas: 100% (10290/10290), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/geohot/tinygrad.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd tinygrad/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KkUngeGcnlV",
        "outputId": "6a4dd4cb-7d46-4e04-9884-ae9a3cfd8c48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/tinygrad\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m pip install -e ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoZj5P_Ecniz",
        "outputId": "46453cd7-a496-4928-bfc6-9f2389bcd4b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/tinygrad\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tinygrad==0.6.0) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from tinygrad==0.6.0) (2.27.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from tinygrad==0.6.0) (8.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tinygrad==0.6.0) (4.65.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from tinygrad==0.6.0) (3.1)\n",
            "Collecting pyopencl (from tinygrad==0.6.0)\n",
            "  Downloading pyopencl-2023.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (919 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m919.2/919.2 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from tinygrad==0.6.0) (6.0)\n",
            "Collecting pytools>=2021.2.7 (from pyopencl->tinygrad==0.6.0)\n",
            "  Downloading pytools-2023.1-py2.py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pyopencl->tinygrad==0.6.0) (3.7.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->tinygrad==0.6.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->tinygrad==0.6.0) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->tinygrad==0.6.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->tinygrad==0.6.0) (3.4)\n",
            "Requirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2021.2.7->pyopencl->tinygrad==0.6.0) (4.6.3)\n",
            "Installing collected packages: pytools, pyopencl, tinygrad\n",
            "  Running setup.py develop for tinygrad\n",
            "Successfully installed pyopencl-2023.1.1 pytools-2023.1 tinygrad-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time, sys\n",
        "import json\n",
        "import tqdm\n",
        "import numpy as np\n",
        "from tinygrad.tensor import Tensor\n",
        "from tinygrad.nn import optim\n",
        "import tinygrad.nn as nn\n",
        "from tinygrad.helpers import flatten\n",
        "from tinygrad.nn.optim import SGD, Adam\n",
        "from sklearn.datasets import fetch_openml\n",
        "from tinygrad.state import safe_save, safe_load, get_state_dict, load_state_dict, torch_load"
      ],
      "metadata": {
        "id": "WwIxjuJScngP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False, )\n",
        "print(X.shape, y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DGaEI97cnd3",
        "outputId": "bb5a9bf8-4884-4f32-aba0-63b1ddd3e754"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(70000, 784) (70000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TinyNetModel:\n",
        "    def __init__(self):\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
        "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(in_features=120, out_features=84)\n",
        "        self.fc2 = nn.Linear(in_features=84, out_features=10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.reshape((x.shape[0], 1, 28, 28))\n",
        "        x = self.conv1(x)\n",
        "        x = x.relu()\n",
        "        x = x.avg_pool2d(2)    ## Conv1:  (64, 6, 14, 14)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = x.relu()\n",
        "        x = x.avg_pool2d(2)    ## Conv2:  (64, 16, 5, 5)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = x.relu()\n",
        "\n",
        "        x = x.reshape((x.shape[0], -1))  ## Reshape:  (64, 120)\n",
        "\n",
        "        x = self.fc1(x)  ## FC1:  (64, 84)\n",
        "        x = x.relu()\n",
        "\n",
        "        x = self.fc2(x)   ## FC2:  (64, 10)\n",
        "        return x.log_softmax()\n",
        "\n",
        "net = TinyNetModel()"
      ],
      "metadata": {
        "id": "-EcYta-YcnbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Tensor.training = True"
      ],
      "metadata": {
        "id": "kZr09iSWcnYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from extra.training import sparse_categorical_crossentropy\n",
        "def cross_entropy(out, Y):\n",
        "  num_classes = out.shape[-1]\n",
        "  YY = Y.flatten().astype(np.int32)\n",
        "  y = np.zeros((YY.shape[0], num_classes), np.float32)\n",
        "  y[range(y.shape[0]),YY] = -1.0*num_classes\n",
        "  y = y.reshape(list(Y.shape)+[num_classes])\n",
        "  y = Tensor(y)\n",
        "  return out.mul(y).mean()"
      ],
      "metadata": {
        "id": "Nj9nwOMOdBWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = Adam([net.conv1.weight, net.conv2.weight, net.conv3.weight], lr=3e-4)"
      ],
      "metadata": {
        "id": "GXWm9BMLdBUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 2000\n",
        "\n",
        "running_loss, correct, total = 0.0, 0.0, 0.0\n",
        "for epoch in range(num_epochs):\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Randomly sample a batch\n",
        "    samp = np.random.randint(0, X.shape[0], size=(64))\n",
        "    batch = Tensor(X[samp].astype('float32') / 255.0, requires_grad=False)\n",
        "    # Get the corresponding labels\n",
        "    labels = y[samp]\n",
        "\n",
        "    # Forward pass\n",
        "    out = net.forward(batch)\n",
        "\n",
        "    # Compute loss\n",
        "    loss = cross_entropy(out, labels)\n",
        "\n",
        "    # Zero gradients\n",
        "    opt.zero_grad()\n",
        "\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "\n",
        "    # Update parameters\n",
        "    opt.step()\n",
        "\n",
        "    # Calculate accuracy\n",
        "    pred = np.argmax(out.numpy(), axis=-1)\n",
        "    labels = [eval(label) for label in labels]\n",
        "\n",
        "    acc = (pred == labels).mean()\n",
        "    if epoch % 100 == 0:\n",
        "      print(f\"Time Taken: {time.time()-start_time:.3f}s, Epoch [{epoch+1}/{num_epochs}], Loss: {loss.numpy():.5f}, Accuracy: {acc:.5f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FMHZunrdBRd",
        "outputId": "e66d7562-73b4-4fa0-bd36-31809b2ae590"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time Taken: 0.360s, Epoch [1/2000], Loss: 2.29161, Accuracy: 0.12500\n",
            "Time Taken: 0.193s, Epoch [101/2000], Loss: 1.92328, Accuracy: 0.68750\n",
            "Time Taken: 0.202s, Epoch [201/2000], Loss: 0.71991, Accuracy: 0.85938\n",
            "Time Taken: 0.200s, Epoch [301/2000], Loss: 0.53938, Accuracy: 0.85938\n",
            "Time Taken: 0.199s, Epoch [401/2000], Loss: 0.54275, Accuracy: 0.76562\n",
            "Time Taken: 0.206s, Epoch [501/2000], Loss: 0.36100, Accuracy: 0.92188\n",
            "Time Taken: 0.193s, Epoch [601/2000], Loss: 0.62642, Accuracy: 0.76562\n",
            "Time Taken: 0.194s, Epoch [701/2000], Loss: 0.25249, Accuracy: 0.95312\n",
            "Time Taken: 0.208s, Epoch [801/2000], Loss: 0.49148, Accuracy: 0.84375\n",
            "Time Taken: 0.208s, Epoch [901/2000], Loss: 0.64140, Accuracy: 0.82812\n",
            "Time Taken: 0.325s, Epoch [1001/2000], Loss: 0.25148, Accuracy: 0.96875\n",
            "Time Taken: 0.196s, Epoch [1101/2000], Loss: 0.51045, Accuracy: 0.87500\n",
            "Time Taken: 0.198s, Epoch [1201/2000], Loss: 0.15379, Accuracy: 0.95312\n",
            "Time Taken: 0.199s, Epoch [1301/2000], Loss: 0.42848, Accuracy: 0.90625\n",
            "Time Taken: 0.207s, Epoch [1401/2000], Loss: 0.28040, Accuracy: 0.93750\n",
            "Time Taken: 0.199s, Epoch [1501/2000], Loss: 0.30147, Accuracy: 0.89062\n",
            "Time Taken: 0.192s, Epoch [1601/2000], Loss: 0.30593, Accuracy: 0.92188\n",
            "Time Taken: 0.203s, Epoch [1701/2000], Loss: 0.18307, Accuracy: 0.93750\n",
            "Time Taken: 0.197s, Epoch [1801/2000], Loss: 0.27549, Accuracy: 0.90625\n",
            "Time Taken: 0.206s, Epoch [1901/2000], Loss: 0.41639, Accuracy: 0.85938\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set training flag to false\n",
        "Tensor.training = False\n",
        "\n",
        "st = time.perf_counter()\n",
        "avg_acc = 0\n",
        "for step in range(1000):\n",
        "  # random sample a batch\n",
        "  samp = np.random.randint(0, X.shape[0], size=(64))\n",
        "  batch = Tensor((X[samp].astype('float32') / 255.0), requires_grad=False)\n",
        "  # get the corresponding labels\n",
        "  labels = y[samp]\n",
        "\n",
        "  # forward pass\n",
        "  out = net.forward(batch)\n",
        "\n",
        "  # calculate accuracy\n",
        "  pred = np.argmax(out.numpy(), axis=-1)\n",
        "\n",
        "  labels = [eval(label) for label in labels]\n",
        "  avg_acc += (pred == labels).mean()\n",
        "\n",
        "print(f\"Test Accuracy: {avg_acc / 1000}\")\n",
        "print(f\"Time Taken To Test: {time.perf_counter() - st}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNp-IKwRdBOk",
        "outputId": "3c29b7e2-a2a5-4cb7-f332-1b753f529029"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.926109375\n",
            "Time Taken To Test: 55.83690177400001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# first we need the state dict of our model\n",
        "state_dict = get_state_dict(net)\n",
        "\n",
        "# then we can just save it to a file\n",
        "safe_save(state_dict, \"/content/model.safetensors\")"
      ],
      "metadata": {
        "id": "Ai4FSZPFdKzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ## weight/bias values into the float-32 format\n",
        "\n",
        "# def list_to_string_val(flatten_list):\n",
        "#   return \" \".join(str(item) for item in flatten_list)\n",
        "\n",
        "\n",
        "# def get_float_list(ndim_list):\n",
        "#     value_list = list(ndim_list.numpy())\n",
        "#     return value_list\n",
        "\n",
        "\n",
        "# def get_weight_bias_file(model_state_dict):\n",
        "#   for key, value in model_state_dict.items():\n",
        "#     model_value_list = np.array(get_float_list(value)).flatten()\n",
        "#     list_to_string = list_to_string_val(model_value_list)\n",
        "#     with open('/content/weight_bias_model.txt','ab') as f:\n",
        "#         f.write(str.encode(list_to_string))\n",
        "#         f.write(str.encode(\"\\n\"))\n",
        "\n",
        "# get_weight_bias_file(state_dict)"
      ],
      "metadata": {
        "id": "U2h0pM99dKwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ### weight/bias values into the int format\n",
        "\n",
        "def float32_to_int(num):\n",
        "    scaled_num = int(round(num * 1000))\n",
        "    return scaled_num\n",
        "\n",
        "\n",
        "def list_to_string_val(flatten_list):\n",
        "    int_list = [float32_to_int(item) for item in flatten_list]  # Convert float values to integers\n",
        "    return \" \".join(str(item) for item in int_list)\n",
        "\n",
        "\n",
        "def get_float_list(ndim_list):\n",
        "    value_list = list(ndim_list.numpy())\n",
        "    return value_list\n",
        "\n",
        "\n",
        "def get_weight_bias_file(model_state_dict):\n",
        "    for key, value in model_state_dict.items():\n",
        "        model_value_list = np.array(get_float_list(value)).flatten()\n",
        "        list_to_string = list_to_string_val(model_value_list)\n",
        "        with open('/content/weight_bias_model_int.txt', 'ab') as f:\n",
        "            f.write(str.encode(list_to_string))\n",
        "            f.write(str.encode(\"\\n\"))\n",
        "\n",
        "get_weight_bias_file(state_dict)"
      ],
      "metadata": {
        "id": "E5PqJQS5dKtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def list_to_string_val(flatten_list):\n",
        "#   return \" \".join(str(item) for item in flatten_list)\n",
        "\n",
        "def float32_to_int(num):\n",
        "    scaled_num = int(round(num * 1000))\n",
        "    return scaled_num\n",
        "\n",
        "def list_to_string_val(flatten_list):\n",
        "    int_list = [float32_to_int(item) for item in flatten_list]  # Convert float values to integers\n",
        "    return \" \".join(str(item) for item in int_list)\n",
        "\n",
        "\n",
        "def extract_feature_map(x):\n",
        "  feature_map = x.numpy().flatten()\n",
        "  feature_map_string_values = list_to_string_val(feature_map)\n",
        "\n",
        "  with open('/content/feature_map_test_int.txt','ab') as f:\n",
        "          f.write(str.encode(feature_map_string_values))\n",
        "          f.write(str.encode(\"\\n\"))"
      ],
      "metadata": {
        "id": "OhbqDrLXdBLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TinyNetTestModel:\n",
        "    def __init__(self):\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
        "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(in_features=120, out_features=84)\n",
        "        self.fc2 = nn.Linear(in_features=84, out_features=10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.reshape((x.shape[0], 1, 28, 28))\n",
        "        extract_feature_map(x) # 0\n",
        "        x = self.conv1(x)\n",
        "        extract_feature_map(x) # 1\n",
        "        x = x.relu()\n",
        "        extract_feature_map(x) # 2\n",
        "\n",
        "        x = x.avg_pool2d(2)    ## Conv1:  (1, 6, 14, 14)\n",
        "        extract_feature_map(x) # 3\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        extract_feature_map(x)   # 4\n",
        "        # print(\"shape of conv2: \", x.shape)\n",
        "        x = x.relu()\n",
        "        extract_feature_map(x) # 5\n",
        "\n",
        "        x = x.avg_pool2d(2)    ## Conv2:  (1, 16, 5, 5)\n",
        "        extract_feature_map(x) # 6\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        extract_feature_map(x)  # 7\n",
        "        x = x.relu()\n",
        "        # print(\"shape of conv3: \", x.shape)\n",
        "        extract_feature_map(x) # 8\n",
        "\n",
        "        x = x.reshape((x.shape[0], -1))  ## Reshape:  (1, 120)\n",
        "        extract_feature_map(x) # 9\n",
        "\n",
        "        x = self.fc1(x)  ## FC1:  (1, 84)\n",
        "        extract_feature_map(x) # 10\n",
        "        x = x.relu()\n",
        "        extract_feature_map(x) # 11\n",
        "\n",
        "        x = self.fc2(x)   ## FC2:  (1, 10)\n",
        "        extract_feature_map(x) # 12\n",
        "        return x.log_softmax()\n",
        "\n",
        "checkpoints = {\n",
        "    'conv1.weight': state_dict['conv1.weight'],\n",
        "    'conv1.bias': state_dict['conv1.bias'],\n",
        "    'conv2.weight': state_dict['conv2.weight'],\n",
        "    'conv2.bias': state_dict['conv2.bias'],\n",
        "    'conv3.weight': state_dict['conv3.weight'],\n",
        "    'conv3.bias': state_dict['conv3.bias'],\n",
        "    'fc1.weight': state_dict['fc1.weight'],\n",
        "    'fc1.bias': state_dict['fc1.bias'],\n",
        "    'fc2.weight': state_dict['fc2.weight'],\n",
        "    'fc2.bias': state_dict['fc2.bias']\n",
        "}\n",
        "\n",
        "model = TinyNetTestModel()\n",
        "load_state_dict(model, checkpoints)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YT5YFCaodBJO",
        "outputId": "b0570d41-8d83-4f20-9174-5736bdd3e1ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ram used:  0.28 GB, fc2.bias                                          : 100%|██████████| 10/10 [00:00<00:00, 614.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loaded weights in 19.70 ms, 0.28 GB loaded at 14.41 GB/s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference on Unseen Image"
      ],
      "metadata": {
        "id": "uLX0X7CqszbQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = [\n",
        "      0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\n",
        "      0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\n",
        "      0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\n",
        "      0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,84,\n",
        "      185,159,151,60,36,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,222,254,254,254,254,241,198,198,198,198,\n",
        "      198,198,198,198,170,52,0,0,0,0,0,0,0,0,0,0,0,0,67,114,72,114,163,227,254,225,254,254,254,250,229,254,\n",
        "      254,140,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,17,66,14,67,67,67,59,21,236,254,106,0,0,0,0,0,0,0,0,0,0,0,\n",
        "      0,0,0,0,0,0,0,0,0,0,0,0,0,83,253,209,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,22,233,255,83,\n",
        "      0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,129,254,238,44,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\n",
        "      0,0,0,0,59,249,254,62,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,133,254,187,5,0,0,0,0,0,0,0,0,\n",
        "      0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,205,248,58,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,126,254,182,\n",
        "      0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,75,251,240,57,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\n",
        "      0,0,0,19,221,254,166,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,203,254,219,35,0,0,0,0,0,0,0,0,0,\n",
        "      0,0,0,0,0,0,0,0,0,0,0,0,0,0,38,254,254,77,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,31,224,254,115,\n",
        "      1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,133,254,254,52,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\n",
        "      0,0,0,61,242,254,254,52,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,121,254,254,219,40,0,0,0,0,0,0,0,\n",
        "      0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,121,254,207,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\n",
        "      0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
        "]"
      ],
      "metadata": {
        "id": "MrNBLlqvdjb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = np.array(img)\n",
        "image = img.astype(np.float32)/255.0\n",
        "# print(image)\n",
        "np.set_printoptions(formatter={'float_kind':'{:f}'.format})\n",
        "\n",
        "preprocessed_image = image.reshape((1, 1, 28, 28))"
      ],
      "metadata": {
        "id": "dhUlDtk0djWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Tensor.training = False\n",
        "input_tensor = Tensor(preprocessed_image)  # Create a tensor from the preprocessed image\n",
        "output_tensor = model.forward(input_tensor)\n",
        "predicted_class= np.argmax(output_tensor.numpy(), axis=-1)\n",
        "\n",
        "np.set_printoptions(formatter={'float_kind':'{:f}'.format})\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "print(\"Predicted class:\", predicted_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdqj4xcOdjTo",
        "outputId": "eb1fef34-4a14-4cca-dc5d-78405411b1a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: [7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Accuracy Score"
      ],
      "metadata": {
        "id": "XVa-QiRWmO74"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/mnist_test.csv\"\n",
        "\n",
        "data = np.loadtxt(file_path, delimiter=\",\")\n",
        "\n",
        "X_test = data[:, 1:]\n",
        "y_test = data[:, 0]\n",
        "\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nppKSwbldjRL",
        "outputId": "cb74125c-90ef-42de-dcbb-d7a70061482b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape: (10000, 784)\n",
            "y_test shape: (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "avg_acc, correct_pred, false_pred = 0, 0, 0\n",
        "batch_size = 128\n",
        "\n",
        "num_batches = int(np.ceil(len(X_test) / batch_size))\n",
        "for i in range(num_batches):\n",
        "    start_idx = i * batch_size\n",
        "    end_idx = min((i + 1) * batch_size, len(X_test))\n",
        "\n",
        "    batch_images = X_test[start_idx:end_idx].reshape((-1, 1, 28, 28))\n",
        "    input_tensor = Tensor(batch_images)  # Convert the batch of preprocessed images to a tensor\n",
        "\n",
        "    output_tensor = model.forward(input_tensor)\n",
        "    predicted_classes = np.argmax(output_tensor.numpy(), axis=-1)\n",
        "\n",
        "    actual_labels = y_test[start_idx:end_idx].astype(int)\n",
        "\n",
        "    avg_acc += np.sum(predicted_classes == actual_labels)\n",
        "    correct_pred += np.sum(predicted_classes == actual_labels)\n",
        "    false_pred += np.sum(predicted_classes != actual_labels)\n",
        "\n",
        "avg_acc /= len(X_test)\n",
        "\n",
        "print(\"Accuracy of Prediction: \", avg_acc)\n",
        "print(\"True Positive Value: \", correct_pred)\n",
        "print(\"False Negative Value: \", false_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-EMnM0vmel4",
        "outputId": "9a2fd1a6-04f2-460e-9133-ddefa2fcb2b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Prediction:  0.9383\n",
            "True Positive Value:  9383\n",
            "False Negative Value:  617\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iPPIqcnimejY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "duM_-K5mmegm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uiNA3J_tmedx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}