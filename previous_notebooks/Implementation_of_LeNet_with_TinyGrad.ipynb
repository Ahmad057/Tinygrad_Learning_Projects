{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPW_xLihU1-5",
        "outputId": "3d3bd959-c40e-41b8-a6bb-d06e6ae4e806"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'tinygrad'...\n",
            "remote: Enumerating objects: 14649, done.\u001b[K\n",
            "remote: Counting objects: 100% (2046/2046), done.\u001b[K\n",
            "remote: Compressing objects: 100% (454/454), done.\u001b[K\n",
            "remote: Total 14649 (delta 1813), reused 1695 (delta 1591), pack-reused 12603\u001b[K\n",
            "Receiving objects: 100% (14649/14649), 18.45 MiB | 23.13 MiB/s, done.\n",
            "Resolving deltas: 100% (10342/10342), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/geohot/tinygrad.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd tinygrad/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCNpn6GGU-vx",
        "outputId": "50e41f14-dded-4d44-bf0e-3448091b87a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/tinygrad\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m pip install -e ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neae3mR3U-tP",
        "outputId": "edd67535-26ec-4682-f361-e24a3037769c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/tinygrad\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tinygrad==0.6.0) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from tinygrad==0.6.0) (2.27.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from tinygrad==0.6.0) (8.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tinygrad==0.6.0) (4.65.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from tinygrad==0.6.0) (3.1)\n",
            "Collecting pyopencl (from tinygrad==0.6.0)\n",
            "  Downloading pyopencl-2023.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (919 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m919.2/919.2 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from tinygrad==0.6.0) (6.0)\n",
            "Collecting pytools>=2021.2.7 (from pyopencl->tinygrad==0.6.0)\n",
            "  Downloading pytools-2023.1-py2.py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pyopencl->tinygrad==0.6.0) (3.7.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->tinygrad==0.6.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->tinygrad==0.6.0) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->tinygrad==0.6.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->tinygrad==0.6.0) (3.4)\n",
            "Requirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2021.2.7->pyopencl->tinygrad==0.6.0) (4.6.3)\n",
            "Installing collected packages: pytools, pyopencl, tinygrad\n",
            "  Running setup.py develop for tinygrad\n",
            "Successfully installed pyopencl-2023.1.1 pytools-2023.1 tinygrad-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time, sys\n",
        "import json\n",
        "import numpy as np\n",
        "from tinygrad.tensor import Tensor\n",
        "from tinygrad.nn import optim\n",
        "import tinygrad.nn as nn\n",
        "from tinygrad.helpers import flatten\n",
        "from tinygrad.nn.optim import SGD, Adam\n",
        "from sklearn.datasets import fetch_openml\n",
        "from tinygrad.state import safe_save, safe_load, get_state_dict, load_state_dict, torch_load"
      ],
      "metadata": {
        "id": "aZcjAhiyU-qn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False, )\n",
        "print(X.shape, y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqZS8wSUU-n3",
        "outputId": "a28e63ba-920e-4d6b-bf3e-958e372133f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(70000, 784) (70000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNetTinyNet:\n",
        "    def __init__(self):\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
        "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(in_features=120, out_features=84)\n",
        "        self.fc2 = nn.Linear(in_features=84, out_features=10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.reshape((x.shape[0], 1, 28, 28))\n",
        "        x = self.conv1(x)\n",
        "        x = x.tanh()\n",
        "        x = x.avg_pool2d(2)    ## Conv1:  (64, 6, 14, 14)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = x.tanh()\n",
        "        x = x.avg_pool2d(2)    ## Conv2:  (64, 16, 5, 5)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = x.tanh()\n",
        "\n",
        "        x = x.reshape((x.shape[0], -1))  ## Reshape:  (64, 120)\n",
        "\n",
        "        x = self.fc1(x)  ## FC1:  (64, 84)\n",
        "        x = x.tanh()\n",
        "\n",
        "        x = self.fc2(x)   ## FC2:  (64, 10)\n",
        "        return x.log_softmax()\n",
        "\n",
        "net = LeNetTinyNet()"
      ],
      "metadata": {
        "id": "Hb8oBtAnU-lS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Tensor.training = True"
      ],
      "metadata": {
        "id": "jIiwRQNXU-iw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from extra.training import sparse_categorical_crossentropy\n",
        "def cross_entropy(out, Y):\n",
        "  num_classes = out.shape[-1]\n",
        "  YY = Y.flatten().astype(np.int32)\n",
        "  y = np.zeros((YY.shape[0], num_classes), np.float32)\n",
        "  y[range(y.shape[0]),YY] = -1.0*num_classes\n",
        "  y = y.reshape(list(Y.shape)+[num_classes])\n",
        "  y = Tensor(y)\n",
        "  return out.mul(y).mean()"
      ],
      "metadata": {
        "id": "DstKdLJTU-f5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = Adam([net.conv1.weight, net.conv2.weight, net.conv3.weight], lr=3e-4)"
      ],
      "metadata": {
        "id": "hXqNWAErVI-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 2000\n",
        "\n",
        "weight_bias_dictionary = {}\n",
        "running_loss, correct, total = 0.0, 0.0, 0.0\n",
        "for epoch in range(num_epochs):\n",
        "    weigth_bias = {}\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Randomly sample a batch\n",
        "    samp = np.random.randint(0, X.shape[0], size=(64))\n",
        "    batch = Tensor(X[samp].astype('float32') / 255.0, requires_grad=False)\n",
        "    # Get the corresponding labels\n",
        "    labels = y[samp]\n",
        "\n",
        "    # Forward pass\n",
        "    out = net.forward(batch)\n",
        "\n",
        "    # Compute loss\n",
        "    loss = cross_entropy(out, labels)\n",
        "\n",
        "    # Zero gradients\n",
        "    opt.zero_grad()\n",
        "\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "\n",
        "    # Update parameters\n",
        "    opt.step()\n",
        "\n",
        "    # Calculate accuracy\n",
        "    pred = np.argmax(out.numpy(), axis=-1)\n",
        "    labels = [eval(label) for label in labels]\n",
        "\n",
        "    acc = (pred == labels).mean()\n",
        "    if epoch % 100 == 0:\n",
        "      print(f\"Time Taken: {time.time()-start_time:.3f}s, Epoch [{epoch+1}/{num_epochs}], Loss: {loss.numpy():.5f}, Accuracy: {acc:.5f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aQm6Y5aVI8Q",
        "outputId": "8e1ae089-38cb-49c1-e054-914a074807f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time Taken: 0.440s, Epoch [1/2000], Loss: 2.29542, Accuracy: 0.14062\n",
            "Time Taken: 0.379s, Epoch [101/2000], Loss: 1.58329, Accuracy: 0.78125\n",
            "Time Taken: 0.245s, Epoch [201/2000], Loss: 1.29733, Accuracy: 0.89062\n",
            "Time Taken: 0.246s, Epoch [301/2000], Loss: 1.20763, Accuracy: 0.87500\n",
            "Time Taken: 0.243s, Epoch [401/2000], Loss: 1.23674, Accuracy: 0.82812\n",
            "Time Taken: 0.230s, Epoch [501/2000], Loss: 1.07521, Accuracy: 0.92188\n",
            "Time Taken: 0.249s, Epoch [601/2000], Loss: 1.08164, Accuracy: 0.92188\n",
            "Time Taken: 0.225s, Epoch [701/2000], Loss: 1.09325, Accuracy: 0.87500\n",
            "Time Taken: 0.246s, Epoch [801/2000], Loss: 1.06176, Accuracy: 0.89062\n",
            "Time Taken: 0.247s, Epoch [901/2000], Loss: 1.04841, Accuracy: 0.89062\n",
            "Time Taken: 0.240s, Epoch [1001/2000], Loss: 1.04766, Accuracy: 0.90625\n",
            "Time Taken: 0.246s, Epoch [1101/2000], Loss: 1.03908, Accuracy: 0.89062\n",
            "Time Taken: 0.388s, Epoch [1201/2000], Loss: 1.01787, Accuracy: 0.90625\n",
            "Time Taken: 0.394s, Epoch [1301/2000], Loss: 1.00754, Accuracy: 0.90625\n",
            "Time Taken: 0.390s, Epoch [1401/2000], Loss: 0.93782, Accuracy: 0.93750\n",
            "Time Taken: 0.238s, Epoch [1501/2000], Loss: 1.04289, Accuracy: 0.93750\n",
            "Time Taken: 0.244s, Epoch [1601/2000], Loss: 0.89453, Accuracy: 0.93750\n",
            "Time Taken: 0.243s, Epoch [1701/2000], Loss: 0.92944, Accuracy: 0.96875\n",
            "Time Taken: 0.249s, Epoch [1801/2000], Loss: 0.94778, Accuracy: 0.92188\n",
            "Time Taken: 0.236s, Epoch [1901/2000], Loss: 0.95101, Accuracy: 0.92188\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set training flag to false\n",
        "Tensor.training = False\n",
        "\n",
        "st = time.perf_counter()\n",
        "avg_acc = 0\n",
        "for step in range(1000):\n",
        "  # random sample a batch\n",
        "  samp = np.random.randint(0, X.shape[0], size=(64))\n",
        "  batch = Tensor((X[samp].astype('float32') / 255.0), requires_grad=False)\n",
        "  # get the corresponding labels\n",
        "  labels = y[samp]\n",
        "\n",
        "  # forward pass\n",
        "  out = net.forward(batch)\n",
        "\n",
        "  # calculate accuracy\n",
        "  pred = np.argmax(out.numpy(), axis=-1)\n",
        "\n",
        "  labels = [eval(label) for label in labels]\n",
        "  avg_acc += (pred == labels).mean()\n",
        "\n",
        "print(f\"Test Accuracy: {avg_acc / 1000}\")\n",
        "print(f\"Time Taken To Test: {time.perf_counter() - st}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJfkxJ3tVI5i",
        "outputId": "a84b13d8-c843-495d-ce94-ef00131dd3ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.931875\n",
            "Time Taken To Test: 81.81800240500002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# first we need the state dict of our model\n",
        "state_dict = get_state_dict(net)\n",
        "\n",
        "# then we can just save it to a file\n",
        "safe_save(state_dict, \"/content/model.safetensors\")"
      ],
      "metadata": {
        "id": "qxVWX2rUVI28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://i.stack.imgur.com/VChE0.png"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKfbJX92VTZA",
        "outputId": "03466fe5-bd0e-4581-e615-4a281321e2d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-06 06:56:37--  https://i.stack.imgur.com/VChE0.png\n",
            "Resolving i.stack.imgur.com (i.stack.imgur.com)... 146.75.28.193\n",
            "Connecting to i.stack.imgur.com (i.stack.imgur.com)|146.75.28.193|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 307274 (300K) [image/png]\n",
            "Saving to: ‘VChE0.png’\n",
            "\n",
            "\rVChE0.png             0%[                    ]       0  --.-KB/s               \rVChE0.png           100%[===================>] 300.07K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2023-07-06 06:56:37 (7.98 MB/s) - ‘VChE0.png’ saved [307274/307274]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tinygrad.tensor as tensor\n",
        "from PIL import Image\n",
        "# Step 1: Preprocess the image\n",
        "# Your preprocessing code here\n",
        "image = Image.open('/content/tinygrad/VChE0.png')\n",
        "image = image.resize((28, 28))  # Resize the image to match the input size of the model\n",
        "\n",
        "# Step 2: Load the trained model\n",
        "state_dict = safe_load(\"/content/model.safetensors\")\n",
        "\n",
        "checkpoints = {\n",
        "    'conv1.weight': state_dict['conv1.weight'],\n",
        "    'conv1.bias': state_dict['conv1.bias'],\n",
        "    'conv2.weight': state_dict['conv2.weight'],\n",
        "    'conv2.bias': state_dict['conv2.bias'],\n",
        "    'conv3.weight': state_dict['conv3.weight'],\n",
        "    'conv3.bias': state_dict['conv3.bias'],\n",
        "    'fc1.weight': state_dict['fc1.weight'],\n",
        "    'fc1.bias': state_dict['fc1.bias'],\n",
        "    'fc2.weight': state_dict['fc2.weight'],\n",
        "    'fc2.bias': state_dict['fc2.bias']\n",
        "}\n",
        "\n",
        "model = LeNetTinyNet()\n",
        "\n",
        "load_state_dict(model, checkpoints)\n",
        "\n",
        "image = image.convert(\"L\")\n",
        "\n",
        "image = np.array(image)\n",
        "\n",
        "image = image.astype(np.float32) / 255.0  # Normalize pixel values to the range [0, 1]\n",
        "\n",
        "start_time = time.time()\n",
        "preprocessed_image = image.reshape((1, 1, 28, 28))\n",
        "\n",
        "# Step 3: Forward pass\n",
        "input_tensor = tensor.Tensor(preprocessed_image)  # Create a tensor from the preprocessed image\n",
        "output_tensor = net.forward(input_tensor)  # Perform forward pass\n",
        "\n",
        "print(f\"\\n\\nTime Taken to Predict the class: {time.time() - start_time: .4f}\")\n",
        "\n",
        "# Step 4: Obtain predictions\n",
        "predicted_class= np.argmax(output_tensor.numpy(), axis=-1)\n",
        "print(\"Predicted class:\", predicted_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnH1qLRjVTWU",
        "outputId": "e6f1d301-2558-4346-de0a-141c35d7358a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ram used:  0.30 GB, fc2.bias                                          : 100%|██████████| 10/10 [00:00<00:00, 469.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loaded weights in 29.61 ms, 0.30 GB loaded at 10.15 GB/s\n",
            "\n",
            "\n",
            "Time Taken to Predict the class:  0.0295\n",
            "Predicted class: [2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VPWS83ktVTTh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}