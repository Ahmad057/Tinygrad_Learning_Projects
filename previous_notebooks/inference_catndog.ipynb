{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, sys\n",
    "import json\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tinygrad.tensor import Tensor\n",
    "from tinygrad.nn import optim, BatchNorm2d\n",
    "import tinygrad.nn as nn\n",
    "from tinygrad.helpers import flatten\n",
    "from tinygrad.nn.optim import SGD, Adam\n",
    "from sklearn.datasets import fetch_openml\n",
    "from tinygrad.state import safe_save, safe_load, get_state_dict, load_state_dict, torch_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = {}\n",
    "file = open(\"weight_bias_model.txt\", \"r\")\n",
    "\n",
    "conv1_weights = file.readline()\n",
    "conv1_bias = file.readline()\n",
    "\n",
    "conv2_weights = file.readline()\n",
    "conv2_bias = file.readline()\n",
    "\n",
    "conv3_weights = file.readline()\n",
    "conv3_bias = file.readline()\n",
    "\n",
    "fc1_weights = file.readline()\n",
    "fc1_bias = file.readline()\n",
    "\n",
    "fc2_weights = file.readline()\n",
    "fc2_bias = file.readline()\n",
    "\n",
    "fc3_weights = file.readline()\n",
    "fc3_bias = file.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_weight_bias_format(data, shape):\n",
    "    data = data.split(\" \")\n",
    "    data = list(map(float, data))\n",
    "    return np.array(data).reshape(shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1_weights = set_weight_bias_format(conv1_weights, (16, 3, 5, 5))\n",
    "conv1_bias = set_weight_bias_format(conv1_bias, 16)\n",
    "\n",
    "conv2_weights = set_weight_bias_format(conv2_weights, (32, 16, 5, 5))\n",
    "conv2_bias = set_weight_bias_format(conv2_bias, (32))\n",
    "\n",
    "conv3_weights = set_weight_bias_format(conv3_weights, (64, 32, 3, 3))\n",
    "conv3_bias = set_weight_bias_format(conv3_bias, (64))\n",
    "\n",
    "fc1_weights = set_weight_bias_format(fc1_weights, (500, 2304))\n",
    "fc1_bias = set_weight_bias_format(fc1_bias, (500))\n",
    "\n",
    "fc2_weights = set_weight_bias_format(fc2_weights, (50, 500))\n",
    "fc2_bias = set_weight_bias_format(fc2_bias, (50))\n",
    "\n",
    "fc3_weights = set_weight_bias_format(fc3_weights, (2, 50))\n",
    "fc3_bias = set_weight_bias_format(fc3_bias, (2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict[\"conv1.weight\"] = Tensor(conv1_weights.astype(np.float32))\n",
    "state_dict[\"conv1.bias\"] = Tensor(conv1_bias.astype(np.float32))\n",
    "\n",
    "state_dict[\"conv2.weight\"] = Tensor(conv2_weights.astype(np.float32))\n",
    "state_dict[\"conv2.bias\"] = Tensor(conv2_bias.astype(np.float32))\n",
    "\n",
    "state_dict[\"conv3.weight\"] = Tensor(conv3_weights.astype(np.float32))\n",
    "state_dict[\"conv3.bias\"] = Tensor(conv3_bias.astype(np.float32))\n",
    "\n",
    "state_dict[\"fc1.weight\"] = Tensor(fc1_weights.astype(np.float32))\n",
    "state_dict[\"fc1.bias\"] = Tensor(fc1_bias.astype(np.float32))\n",
    "\n",
    "state_dict[\"fc2.weight\"] = Tensor(fc2_weights.astype(np.float32))\n",
    "state_dict[\"fc2.bias\"] = Tensor(fc2_bias.astype(np.float32))\n",
    "\n",
    "state_dict[\"fc3.weight\"] = Tensor(fc3_weights.astype(np.float32))\n",
    "state_dict[\"fc3.bias\"] = Tensor(fc3_bias.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_string_val(flatten_list):\n",
    "  return \" \".join(str(item) for item in flatten_list)\n",
    "\n",
    "def float32_to_int(num):\n",
    "    scaled_num = int(round(num * 1000))\n",
    "    return scaled_num\n",
    "\n",
    "def extract_feature_map(x):\n",
    "  feature_map = x.numpy().flatten()\n",
    "  feature_map_string_values = list_to_string_val(feature_map)\n",
    "\n",
    "  with open('feature_map_test.txt','wb') as f:\n",
    "          f.write(str.encode(feature_map_string_values))\n",
    "          f.write(str.encode(\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ram used:  0.00 GB, fc3.bias                                          : 100%|██████████| 12/12 [00:00<00:00, 289.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded weights in 50.61 ms, 0.00 GB loaded at 0.10 GB/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class CustomTinyNet:\n",
    "    def __init__(self):\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=64*6*6, out_features=500)\n",
    "        self.fc2 = nn.Linear(in_features=500, out_features=50)\n",
    "        self.fc3 = nn.Linear(in_features=50, out_features=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape((x.shape[0], 3, 224, 224))\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = x.relu()\n",
    "        x = x.max_pool2d(2)  \n",
    "        # extract_feature_map(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = x.relu()\n",
    "        x = x.max_pool2d(2)        \n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = x.relu()\n",
    "        x = x.max_pool2d(2)         \n",
    "\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "\n",
    "        x = self.fc1(x) \n",
    "        x = x.relu()\n",
    "\n",
    "        x = self.fc2(x) \n",
    "        x = x.relu()\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "        \n",
    "\n",
    "checkpoints = {\n",
    "    'conv1.weight': state_dict['conv1.weight'],\n",
    "    'conv1.bias': state_dict['conv1.bias'],\n",
    "    'conv2.weight': state_dict['conv2.weight'],\n",
    "    'conv2.bias': state_dict['conv2.bias'],\n",
    "    'conv3.weight': state_dict['conv3.weight'],\n",
    "    'conv3.bias': state_dict['conv3.bias'],\n",
    "    'fc1.weight': state_dict['fc1.weight'],\n",
    "    'fc1.bias': state_dict['fc1.bias'],\n",
    "    'fc2.weight': state_dict['fc2.weight'],\n",
    "    'fc2.bias': state_dict['fc2.bias'],\n",
    "    'fc3.weight': state_dict['fc3.weight'],\n",
    "    'fc3.bias': state_dict['fc3.bias']\n",
    "}\n",
    "\n",
    "model = CustomTinyNet()\n",
    "load_state_dict(model, checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "def pytorch_preprocessing(image):  \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Apply the necessary transformations\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    image = transform(image)\n",
    "    image = image.unsqueeze(0) \n",
    "    return Tensor(image.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def inference_model(image):\n",
    "    image = pytorch_preprocessing(image)\n",
    "    start_time = time.time()\n",
    "    output_tensor = model.forward(image) \n",
    "    # print(\"Time Taken: \", time.time()-start_time)\n",
    "\n",
    "    predicted_class= np.argmax(output_tensor.numpy(), axis=-1)\n",
    "    # print(\"Predicted class:\", predicted_class)\n",
    "    return time.time()-start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken:  0.02574324607849121\n",
      "Predicted class: [1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# !wget https://upload.wikimedia.org/wikipedia/commons/d/d0/German_Shepherd_-_DSC_0346_%2810096362833%29.jpg\n",
    "\n",
    "image = Image.open('Dataset/Dog/4.jpg')\n",
    "inference_model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken:  0.017928123474121094\n",
      "Predicted class: [0]\n"
     ]
    }
   ],
   "source": [
    "# !wget https://i.pinimg.com/736x/59/4d/85/594d857129569aa5ea91ae1a696ea730--red-and-white-white-persian-kittens.jpg\n",
    "\n",
    "image = Image.open('Dataset/Cat/4.jpg')\n",
    "inference_model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013648333835601807"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path = os.listdir(\"Dataset/Cat/\")\n",
    "time_taken = 0\n",
    "\n",
    "for img in img_path:\n",
    "    image = Image.open('Dataset/Cat/' + img)\n",
    "    \n",
    "    time_taken += inference_model(image)\n",
    "    \n",
    "\n",
    "time_taken/len(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fa1a39b4d220832bc88fa9bccaa17b58fb936972f35e194156c0c6b088907f4d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
