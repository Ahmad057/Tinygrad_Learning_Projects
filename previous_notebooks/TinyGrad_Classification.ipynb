{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5nws93QJUQt"
      },
      "source": [
        "## Using TinyGrad:-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNzTTsdiLA9J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f661c959-f8a6-47d3-e2fb-a8238ba2038a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'tinygrad'...\n",
            "remote: Enumerating objects: 14499, done.\u001b[K\n",
            "remote: Counting objects: 100% (1897/1897), done.\u001b[K\n",
            "remote: Compressing objects: 100% (350/350), done.\u001b[K\n",
            "remote: Total 14499 (delta 1711), reused 1611 (delta 1547), pack-reused 12602\u001b[K\n",
            "Receiving objects: 100% (14499/14499), 18.41 MiB | 36.38 MiB/s, done.\n",
            "Resolving deltas: 100% (10240/10240), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/geohot/tinygrad.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctlVqGPEpQ7q",
        "outputId": "e4dabcf2-0c80-463d-f40d-696255ca628a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/tinygrad\n"
          ]
        }
      ],
      "source": [
        "cd tinygrad/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xwp6H8tMpUCA",
        "outputId": "4c2639ef-230e-4b8c-fab8-afda184b8f81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/tinygrad\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tinygrad==0.6.0) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from tinygrad==0.6.0) (2.27.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from tinygrad==0.6.0) (8.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tinygrad==0.6.0) (4.65.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from tinygrad==0.6.0) (3.1)\n",
            "Collecting pyopencl (from tinygrad==0.6.0)\n",
            "  Downloading pyopencl-2023.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (919 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m919.2/919.2 kB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from tinygrad==0.6.0) (6.0)\n",
            "Collecting pytools>=2021.2.7 (from pyopencl->tinygrad==0.6.0)\n",
            "  Downloading pytools-2023.1-py2.py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pyopencl->tinygrad==0.6.0) (3.7.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->tinygrad==0.6.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->tinygrad==0.6.0) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->tinygrad==0.6.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->tinygrad==0.6.0) (3.4)\n",
            "Requirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2021.2.7->pyopencl->tinygrad==0.6.0) (4.6.3)\n",
            "Installing collected packages: pytools, pyopencl, tinygrad\n",
            "  Running setup.py develop for tinygrad\n",
            "Successfully installed pyopencl-2023.1.1 pytools-2023.1 tinygrad-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "S8UmAA2uCOZb",
        "outputId": "2e0e4946-ce99-4c45-9dc4-06aba35baf38"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/tinygrad'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYUvS_x2S3zB"
      },
      "source": [
        "### TinyGrad with Mnist dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLMcH8CFCX6I"
      },
      "outputs": [],
      "source": [
        "import time, sys\n",
        "import json\n",
        "import tqdm\n",
        "import numpy as np\n",
        "from tinygrad.tensor import Tensor\n",
        "from tinygrad.nn import optim\n",
        "import tinygrad.nn as nn\n",
        "from tinygrad.helpers import flatten\n",
        "from tinygrad.nn.optim import SGD, Adam\n",
        "from sklearn.datasets import fetch_openml\n",
        "from tinygrad.state import safe_save, safe_load, get_state_dict, load_state_dict, torch_load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-1LtFQXSzWM",
        "outputId": "de1c2d50-f76a-4744-fa6d-71fd96afc8d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(70000, 784) (70000,)\n"
          ]
        }
      ],
      "source": [
        "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False, )\n",
        "print(X.shape, y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVog_df8S-zt"
      },
      "outputs": [],
      "source": [
        "class LeNetTinyNet:\n",
        "    def __init__(self):\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
        "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(in_features=120, out_features=84)\n",
        "        self.fc2 = nn.Linear(in_features=84, out_features=10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.reshape((x.shape[0], 1, 28, 28))\n",
        "        x = self.conv1(x)\n",
        "        x = x.tanh()\n",
        "        x = x.avg_pool2d(2)    ## Conv1:  (64, 6, 14, 14)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = x.tanh()\n",
        "        x = x.avg_pool2d(2)    ## Conv2:  (64, 16, 5, 5)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = x.tanh()\n",
        "\n",
        "        x = x.reshape((x.shape[0], -1))  ## Reshape:  (64, 120)\n",
        "\n",
        "        x = self.fc1(x)  ## FC1:  (64, 84)\n",
        "        x = x.tanh()\n",
        "\n",
        "        x = self.fc2(x)   ## FC2:  (64, 10)\n",
        "        return x.log_softmax()\n",
        "\n",
        "net = LeNetTinyNet()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BYj4zgYTCp9"
      },
      "outputs": [],
      "source": [
        "Tensor.training = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9c0-2B2TCnK"
      },
      "outputs": [],
      "source": [
        "# from extra.training import sparse_categorical_crossentropy\n",
        "def cross_entropy(out, Y):\n",
        "  num_classes = out.shape[-1]\n",
        "  YY = Y.flatten().astype(np.int32)\n",
        "  y = np.zeros((YY.shape[0], num_classes), np.float32)\n",
        "  y[range(y.shape[0]),YY] = -1.0*num_classes\n",
        "  y = y.reshape(list(Y.shape)+[num_classes])\n",
        "  y = Tensor(y)\n",
        "  return out.mul(y).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDt5nG41mw8-"
      },
      "outputs": [],
      "source": [
        "def get_weights(weights):\n",
        "    # Get the float values of the weights as a NumPy array\n",
        "    weights_array = weights.numpy().astype(float)\n",
        "\n",
        "    # Alternatively, get the float values as a Python list\n",
        "    weights_list = list(weights.numpy())\n",
        "    return weights_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Coi79X2STCkW"
      },
      "outputs": [],
      "source": [
        "opt = Adam([net.conv1.weight, net.conv2.weight, net.conv3.weight], lr=3e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvF6YkcxTChK",
        "outputId": "226fd804-18dd-4bbd-92fa-641f58b30c37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time Taken: 0.252s, Epoch [1/2000], Loss: 2.30259, Accuracy: 0.07812\n",
            "Time Taken: 0.233s, Epoch [101/2000], Loss: 1.60009, Accuracy: 0.81250\n",
            "Time Taken: 0.352s, Epoch [201/2000], Loss: 1.31239, Accuracy: 0.82812\n",
            "Time Taken: 0.342s, Epoch [301/2000], Loss: 1.25362, Accuracy: 0.84375\n",
            "Time Taken: 0.363s, Epoch [401/2000], Loss: 1.19342, Accuracy: 0.87500\n",
            "Time Taken: 0.352s, Epoch [501/2000], Loss: 1.10693, Accuracy: 0.85938\n",
            "Time Taken: 0.211s, Epoch [601/2000], Loss: 1.13220, Accuracy: 0.79688\n",
            "Time Taken: 0.250s, Epoch [701/2000], Loss: 1.06580, Accuracy: 0.85938\n",
            "Time Taken: 0.235s, Epoch [801/2000], Loss: 1.01031, Accuracy: 0.95312\n",
            "Time Taken: 0.214s, Epoch [901/2000], Loss: 0.97295, Accuracy: 0.92188\n",
            "Time Taken: 0.230s, Epoch [1001/2000], Loss: 1.06278, Accuracy: 0.85938\n",
            "Time Taken: 0.216s, Epoch [1101/2000], Loss: 0.92644, Accuracy: 0.92188\n",
            "Time Taken: 0.206s, Epoch [1201/2000], Loss: 0.90607, Accuracy: 0.96875\n",
            "Time Taken: 0.248s, Epoch [1301/2000], Loss: 0.98052, Accuracy: 0.90625\n",
            "Time Taken: 0.247s, Epoch [1401/2000], Loss: 1.02679, Accuracy: 0.85938\n",
            "Time Taken: 0.239s, Epoch [1501/2000], Loss: 0.99178, Accuracy: 0.90625\n",
            "Time Taken: 0.231s, Epoch [1601/2000], Loss: 0.91646, Accuracy: 0.93750\n",
            "Time Taken: 0.240s, Epoch [1701/2000], Loss: 0.85374, Accuracy: 0.98438\n",
            "Time Taken: 0.236s, Epoch [1801/2000], Loss: 0.98150, Accuracy: 0.90625\n",
            "Time Taken: 0.234s, Epoch [1901/2000], Loss: 0.95010, Accuracy: 0.90625\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 2000\n",
        "\n",
        "weight_bias_dictionary = {}\n",
        "running_loss, correct, total = 0.0, 0.0, 0.0\n",
        "for epoch in range(num_epochs):\n",
        "    weigth_bias = {}\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Randomly sample a batch\n",
        "    samp = np.random.randint(0, X.shape[0], size=(64))\n",
        "    batch = Tensor(X[samp].astype('float32') / 255.0, requires_grad=False)\n",
        "    # Get the corresponding labels\n",
        "    labels = y[samp]\n",
        "\n",
        "    # Forward pass\n",
        "    out = net.forward(batch)\n",
        "\n",
        "    # Compute loss\n",
        "    loss = cross_entropy(out, labels)\n",
        "\n",
        "    # Zero gradients\n",
        "    opt.zero_grad()\n",
        "\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "\n",
        "    # Update parameters\n",
        "    opt.step()\n",
        "\n",
        "    # Calculate accuracy\n",
        "    pred = np.argmax(out.numpy(), axis=-1)\n",
        "    labels = [eval(label) for label in labels]\n",
        "\n",
        "    acc = (pred == labels).mean()\n",
        "    if epoch % 100 == 0:\n",
        "      print(f\"Time Taken: {time.time()-start_time:.3f}s, Epoch [{epoch+1}/{num_epochs}], Loss: {loss.numpy():.5f}, Accuracy: {acc:.5f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inJmASe0TPjj",
        "outputId": "b9283311-cc99-4019-c0cb-c8d9c2884135"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.93803125\n",
            "Time Taken To Test: 74.64441574900002\n"
          ]
        }
      ],
      "source": [
        "# set training flag to false\n",
        "Tensor.training = False\n",
        "\n",
        "st = time.perf_counter()\n",
        "avg_acc = 0\n",
        "for step in range(1000):\n",
        "  # random sample a batch\n",
        "  samp = np.random.randint(0, X.shape[0], size=(64))\n",
        "  batch = Tensor((X[samp].astype('float32') / 255.0), requires_grad=False)\n",
        "  # get the corresponding labels\n",
        "  labels = y[samp]\n",
        "\n",
        "  # forward pass\n",
        "  out = net.forward(batch)\n",
        "\n",
        "  # calculate accuracy\n",
        "  pred = np.argmax(out.numpy(), axis=-1)\n",
        "\n",
        "  labels = [eval(label) for label in labels]\n",
        "  avg_acc += (pred == labels).mean()\n",
        "\n",
        "print(f\"Test Accuracy: {avg_acc / 1000}\")\n",
        "print(f\"Time Taken To Test: {time.perf_counter() - st}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4AW4Xsy4t80"
      },
      "outputs": [],
      "source": [
        "# first we need the state dict of our model\n",
        "state_dict = get_state_dict(net)\n",
        "\n",
        "# then we can just save it to a file\n",
        "safe_save(state_dict, \"/content/model.safetensors\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Model weights & Bias"
      ],
      "metadata": {
        "id": "DQYu9V_MFRFK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## weight/bias values into the float-32 format\n",
        "\n",
        "def list_to_string_val(flatten_list):\n",
        "  return \" \".join(str(item) for item in flatten_list)\n",
        "\n",
        "\n",
        "def get_float_list(ndim_list):\n",
        "    value_list = list(ndim_list.numpy())\n",
        "    return value_list\n",
        "\n",
        "\n",
        "def get_weight_bias_file(model_state_dict):\n",
        "  for key, value in model_state_dict.items():\n",
        "    print(f\"{key}: {value.shape}, {value[0].shape}\")\n",
        "    model_value_list = np.array(get_float_list(value)).flatten()\n",
        "    list_to_string = list_to_string_val(model_value_list)\n",
        "    with open('/content/weight_bias_model.txt','ab') as f:\n",
        "        f.write(str.encode(list_to_string))\n",
        "        f.write(str.encode(\"\\n\"))"
      ],
      "metadata": {
        "id": "dQpZOW_XFU_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ### weight/bias values into the int format\n",
        "\n",
        "# def float32_to_int(num):\n",
        "#     scaled_num = int(round(num * 1000))\n",
        "#     return scaled_num\n",
        "\n",
        "\n",
        "# def list_to_string_val(flatten_list):\n",
        "#     int_list = [float32_to_int(item) for item in flatten_list]  # Convert float values to integers\n",
        "#     return \" \".join(str(item) for item in int_list)\n",
        "\n",
        "\n",
        "# def get_float_list(ndim_list):\n",
        "#     value_list = list(ndim_list.numpy())\n",
        "#     return value_list\n",
        "\n",
        "\n",
        "# def get_weight_bias_file(model_state_dict):\n",
        "#     for key, value in model_state_dict.items():\n",
        "#         model_value_list = np.array(get_float_list(value)).flatten()\n",
        "#         list_to_string = list_to_string_val(model_value_list)\n",
        "#         with open('/content/weight_bias_model_int.txt', 'ab') as f:\n",
        "#             f.write(str.encode(list_to_string))\n",
        "#             f.write(str.encode(\"\\n\"))"
      ],
      "metadata": {
        "id": "9NxUgrUE0D2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jnxb64nW2Lpb"
      },
      "source": [
        "### Model Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NAHZGQmqZce",
        "outputId": "9950230b-b6e9-4ea0-973d-21c9d4d084db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-04 05:58:59--  https://i.stack.imgur.com/VChE0.png\n",
            "Resolving i.stack.imgur.com (i.stack.imgur.com)... 146.75.32.193\n",
            "Connecting to i.stack.imgur.com (i.stack.imgur.com)|146.75.32.193|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 307274 (300K) [image/png]\n",
            "Saving to: ‘VChE0.png’\n",
            "\n",
            "\rVChE0.png             0%[                    ]       0  --.-KB/s               \rVChE0.png           100%[===================>] 300.07K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2023-07-04 05:58:59 (69.3 MB/s) - ‘VChE0.png’ saved [307274/307274]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://i.stack.imgur.com/VChE0.png"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiWII6Zz2Osy",
        "outputId": "034ead9b-849e-4159-de62-e92b44b52fde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv1.weight: (6, 1, 5, 5), (1, 5, 5)\n",
            "conv1.bias: (6,), ()\n",
            "conv2.weight: (16, 6, 5, 5), (6, 5, 5)\n",
            "conv2.bias: (16,), ()\n",
            "conv3.weight: (120, 16, 5, 5), (16, 5, 5)\n",
            "conv3.bias: (120,), ()\n",
            "fc1.weight: (84, 120), (120,)\n",
            "fc1.bias: (84,), ()\n",
            "fc2.weight: (10, 84), (84,)\n",
            "fc2.bias: (10,), ()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ram used:  0.30 GB, fc2.bias                                          : 100%|██████████| 10/10 [00:00<00:00, 321.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loaded weights in 38.39 ms, 0.30 GB loaded at 7.92 GB/s\n",
            "\n",
            "\n",
            "Time Taken to Predict the class:  0.0229\n",
            "Predicted class: [2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import tinygrad.tensor as tensor\n",
        "from PIL import Image\n",
        "# Step 1: Preprocess the image\n",
        "# Your preprocessing code here\n",
        "image = Image.open('/content/tinygrad/VChE0.png')\n",
        "image = image.resize((28, 28))  # Resize the image to match the input size of the model\n",
        "\n",
        "# Step 2: Load the trained model\n",
        "state_dict = safe_load(\"/content/model.safetensors\")\n",
        "get_weight_bias_file(state_dict)\n",
        "\n",
        "checkpoints = {\n",
        "    'conv1.weight': state_dict['conv1.weight'],\n",
        "    'conv1.bias': state_dict['conv1.bias'],\n",
        "    'conv2.weight': state_dict['conv2.weight'],\n",
        "    'conv2.bias': state_dict['conv2.bias'],\n",
        "    'conv3.weight': state_dict['conv3.weight'],\n",
        "    'conv3.bias': state_dict['conv3.bias'],\n",
        "    'fc1.weight': state_dict['fc1.weight'],\n",
        "    'fc1.bias': state_dict['fc1.bias'],\n",
        "    'fc2.weight': state_dict['fc2.weight'],\n",
        "    'fc2.bias': state_dict['fc2.bias']\n",
        "}\n",
        "\n",
        "model = LeNetTinyNet()\n",
        "\n",
        "load_state_dict(model, checkpoints)\n",
        "\n",
        "image = image.convert(\"L\")\n",
        "\n",
        "image = np.array(image)\n",
        "\n",
        "image = image.astype(np.float32) / 255.0  # Normalize pixel values to the range [0, 1]\n",
        "\n",
        "start_time = time.time()\n",
        "preprocessed_image = image.reshape((1, 1, 28, 28))\n",
        "\n",
        "# Step 3: Forward pass\n",
        "input_tensor = tensor.Tensor(preprocessed_image)  # Create a tensor from the preprocessed image\n",
        "output_tensor = net.forward(input_tensor)  # Perform forward pass\n",
        "\n",
        "print(f\"\\n\\nTime Taken to Predict the class: {time.time() - start_time: .4f}\")\n",
        "\n",
        "# Step 4: Obtain predictions\n",
        "predicted_class= np.argmax(output_tensor.numpy(), axis=-1)\n",
        "print(\"Predicted class:\", predicted_class)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compare the Feature-Map of image"
      ],
      "metadata": {
        "id": "oVBbAnoG_rX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def list_to_string_val(flatten_list):\n",
        "  return \" \".join(str(item) for item in flatten_list)\n",
        "\n",
        "def float32_to_int(num):\n",
        "    scaled_num = int(round(num * 1000))\n",
        "    return scaled_num\n",
        "\n",
        "# def list_to_string_val(flatten_list):\n",
        "#     int_list = [float32_to_int(item) for item in flatten_list]  # Convert float values to integers\n",
        "#     return \" \".join(str(item) for item in int_list)\n",
        "\n",
        "\n",
        "def extract_feature_map(x):\n",
        "  feature_map = x.numpy().flatten()\n",
        "  feature_map_string_values = list_to_string_val(feature_map)\n",
        "\n",
        "  with open('/content/feature_map_test.txt','ab') as f:\n",
        "          f.write(str.encode(feature_map_string_values))\n",
        "          f.write(str.encode(\"\\n\"))"
      ],
      "metadata": {
        "id": "JwI_m1XiIIUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNetTinyNet:\n",
        "    def __init__(self):\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
        "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(in_features=120, out_features=84)\n",
        "        self.fc2 = nn.Linear(in_features=84, out_features=10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.reshape((x.shape[0], 1, 28, 28))\n",
        "        extract_feature_map(x) # 0\n",
        "        x = self.conv1(x)\n",
        "        extract_feature_map(x) # 1\n",
        "        x = x.tanh()\n",
        "        extract_feature_map(x) # 2\n",
        "\n",
        "        x = x.avg_pool2d(2)    ## Conv1:  (1, 6, 14, 14)\n",
        "        extract_feature_map(x) # 3\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        extract_feature_map(x)   # 4\n",
        "        # print(\"shape of conv2: \", x.shape)\n",
        "        x = x.tanh()\n",
        "        extract_feature_map(x) # 5\n",
        "\n",
        "        x = x.avg_pool2d(2)    ## Conv2:  (1, 16, 5, 5)\n",
        "        extract_feature_map(x) # 6\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        extract_feature_map(x)  # 7\n",
        "        x = x.tanh()\n",
        "        # print(\"shape of conv3: \", x.shape)\n",
        "        extract_feature_map(x) # 8\n",
        "\n",
        "        x = x.reshape((x.shape[0], -1))  ## Reshape:  (1, 120)\n",
        "        extract_feature_map(x) # 9\n",
        "\n",
        "        x = self.fc1(x)  ## FC1:  (1, 84)\n",
        "        extract_feature_map(x) # 10\n",
        "        x = x.tanh()\n",
        "        extract_feature_map(x) # 11\n",
        "\n",
        "        x = self.fc2(x)   ## FC2:  (1, 10)\n",
        "        extract_feature_map(x) # 12\n",
        "        return x.log_softmax()\n",
        "\n",
        "checkpoints = {\n",
        "    'conv1.weight': state_dict['conv1.weight'],\n",
        "    'conv1.bias': state_dict['conv1.bias'],\n",
        "    'conv2.weight': state_dict['conv2.weight'],\n",
        "    'conv2.bias': state_dict['conv2.bias'],\n",
        "    'conv3.weight': state_dict['conv3.weight'],\n",
        "    'conv3.bias': state_dict['conv3.bias'],\n",
        "    'fc1.weight': state_dict['fc1.weight'],\n",
        "    'fc1.bias': state_dict['fc1.bias'],\n",
        "    'fc2.weight': state_dict['fc2.weight'],\n",
        "    'fc2.bias': state_dict['fc2.bias']\n",
        "}\n",
        "\n",
        "model = LeNetTinyNet()\n",
        "load_state_dict(model, checkpoints)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haMj921lHsKz",
        "outputId": "1f3fb6bb-9674-4cf4-ad2e-647726c09772"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ram used:  0.30 GB, fc2.bias                                          : 100%|██████████| 10/10 [00:00<00:00, 531.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loaded weights in 25.53 ms, 0.30 GB loaded at 11.91 GB/s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "file_path = \"/content/mnist_test.csv\"\n",
        "\n",
        "data = np.loadtxt(file_path, delimiter=\",\")\n",
        "\n",
        "X_test = data[:, 1:]\n",
        "y_test = data[:, 0]\n",
        "\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n"
      ],
      "metadata": {
        "id": "5zBORcmAHnYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_acc, correct_pred, false_pred = 0, 0, 0\n",
        "batch_size = 128\n",
        "\n",
        "num_batches = int(np.ceil(len(X_test) / batch_size))\n",
        "for i in tqdm(range(num_batches)):\n",
        "    start_idx = i * batch_size\n",
        "    end_idx = min((i + 1) * batch_size, len(X_test))\n",
        "\n",
        "    batch_images = X_test[start_idx:end_idx].reshape((-1, 1, 28, 28))\n",
        "    input_tensor = Tensor(batch_images)  # Convert the batch of preprocessed images to a tensor\n",
        "\n",
        "    output_tensor = model.forward(input_tensor)\n",
        "    predicted_classes = np.argmax(output_tensor.numpy(), axis=-1)\n",
        "\n",
        "    actual_labels = y_test[start_idx:end_idx].astype(int)\n",
        "\n",
        "    avg_acc += np.sum(predicted_classes == actual_labels)\n",
        "    correct_pred += np.sum(predicted_classes == actual_labels)\n",
        "    false_pred += np.sum(predicted_classes != actual_labels)\n",
        "\n",
        "avg_acc /= len(X_test)\n",
        "\n",
        "print(\"Accuracy of Prediction: \", avg_acc)\n",
        "print(\"True Positive Value: \", correct_pred)\n",
        "print(\"False Negative Value: \", false_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ey8Xk-VVMQWt",
        "outputId": "34b13d8f-7abb-45d5-b966-a5d5cf85d521"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [01:51<00:00,  1.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Prediction:  0.9427\n",
            "True Positive Value:  9427\n",
            "False Negative Value:  573\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = [\n",
        "        0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\n",
        "        0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\n",
        "        0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\n",
        "        0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,84,\n",
        "        185,159,151,60,36,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,222,254,254,254,254,241,198,198,198,198,\n",
        "        198,198,198,198,170,52,0,0,0,0,0,0,0,0,0,0,0,0,67,114,72,114,163,227,254,225,254,254,254,250,229,254,\n",
        "        254,140,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,17,66,14,67,67,67,59,21,236,254,106,0,0,0,0,0,0,0,0,0,0,0,\n",
        "        0,0,0,0,0,0,0,0,0,0,0,0,0,83,253,209,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,22,233,255,83,\n",
        "        0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,129,254,238,44,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\n",
        "        0,0,0,0,59,249,254,62,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,133,254,187,5,0,0,0,0,0,0,0,0,\n",
        "        0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,205,248,58,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,126,254,182,\n",
        "        0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,75,251,240,57,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\n",
        "        0,0,0,19,221,254,166,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,203,254,219,35,0,0,0,0,0,0,0,0,0,\n",
        "        0,0,0,0,0,0,0,0,0,0,0,0,0,0,38,254,254,77,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,31,224,254,115,\n",
        "        1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,133,254,254,52,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\n",
        "        0,0,0,61,242,254,254,52,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,121,254,254,219,40,0,0,0,0,0,0,0,\n",
        "        0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,121,254,207,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\n",
        "        0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
        "\n",
        "]"
      ],
      "metadata": {
        "id": "7OIunhSm6YGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = np.array(img)\n",
        "image = img.astype(np.float32)/255.0\n",
        "# print(image)\n",
        "np.set_printoptions(formatter={'float_kind':'{:f}'.format})\n",
        "\n",
        "preprocessed_image = image.reshape((1, 1, 28, 28))"
      ],
      "metadata": {
        "id": "tjO46jwV-9m1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Tensor.training = False\n",
        "input_tensor = Tensor(preprocessed_image)  # Create a tensor from the preprocessed image\n",
        "output_tensor = model.forward(input_tensor)\n",
        "predicted_class= np.argmax(output_tensor.numpy(), axis=-1)\n",
        "\n",
        "np.set_printoptions(formatter={'float_kind':'{:f}'.format})\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "print(\"Predicted class:\", predicted_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y89pmxVI9pRU",
        "outputId": "4d580091-6fe2-40ef-e9fd-88b2a6b307bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: [7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LsDFOT09oeMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Je6CXN3hvQxP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}